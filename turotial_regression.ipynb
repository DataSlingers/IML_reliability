{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3bbe3b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66faeb56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import imlreliability\n",
    "import pandas as pd\n",
    "import numpy as np#### Load Packages dir(imlreliability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9c219",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-prague",
   "metadata": {},
   "source": [
    "Reliability test of feature importance techniques can be performed with the module imlreliability.feature_importance. Non-MLP techniques can be evaluated ``feature_impoReg`` for regression tasks and ``feature_impoClass`` for classification tasks. MLP-based techniques can be evaluated by ``feature_impoReg_MLP`` for regression tasks and ``feature_impoClass_MLP`` for classification tasks. \n",
    "\n",
    "Model agnostic techniques can be evaluated by specifying the parameter of importance function ``importance_func``. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-assist",
   "metadata": {},
   "source": [
    "## 1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e7ef7",
   "metadata": {},
   "source": [
    "#### Load data\n",
    " We use the communities regression data as an example for the following sections. The data has 1993 observations and 99 feature. We pre-process the data set by scaling and normalizing the predictors and scaling the response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beeaba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, normalize\n",
    "communities_data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data').to_numpy()\n",
    "communities_data = np.delete(communities_data, np.arange(5), 1)\n",
    "    # remove predictors with missing values\n",
    "communities_data = np.delete(communities_data,\n",
    "                             np.argwhere((communities_data == '?').sum(0) > 0).reshape(-1), 1)\n",
    "communities_data = communities_data.astype(float)\n",
    "x = communities_data[:, :-1]\n",
    "y = communities_data[:, -1]\n",
    "\n",
    "\n",
    "### scale and normalize data \n",
    "x = normalize(scale(x))\n",
    "y = (scale(y))\n",
    "data_reg=(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305ce6ae",
   "metadata": {},
   "source": [
    "### 1.1. Model specific IML method\n",
    "\n",
    "The estimator is assumed to implement the scikit-learn estimator interface. To measure the feature importance, either estimator needs to provide a ``score`` function or ``scoring`` must be passed. For example, in linear regression, the magnitude of coefficients is used to evaluate feature importance if there is no user-defined scoring function provided. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccc58e",
   "metadata": {},
   "source": [
    "#### 1.1.1. Linear model\n",
    "\n",
    "Here we aim to evaluate the interpretation reliability of Ridge regression with cross validation, using the ``feature_impoReg``function. We use ``RidgeCV()`` from ``sklearn`` as our estimator. By setting ``importance_func=None``, the magnitude of coefficients will be used to evaluate feature importance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7527818e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "estimator=RidgeCV()\n",
    "importance_func=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-divorce",
   "metadata": {},
   "source": [
    "We initialize the model with the ``mlreliability.feature_importance.feature_impoReg`` function. For illustration purpose, we run 3 repeats with 70%/30% train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "known-hartford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n"
     ]
    }
   ],
   "source": [
    "model_reg = imlreliability.feature_importance.feature_impoReg(data_reg,estimator=estimator, \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-federation",
   "metadata": {},
   "source": [
    "The ``.get_consistency`` function results in three pandas dataframe: ``accuracy``: prediction accuracy on test set; ``consistency``: interpretation consistency measured by RBO, Jaccard score, or user-defined metrics; and prediction_consistency measured by prediction entropy and purity if ``get_prediction_consistency ==True``. \n",
    "\n",
    "The ``consistency`` pandas dataframe can be downloaded and upload to the dashboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sought-province",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance Function is  Coef_Ridge\n",
      "          data  model  Accuracy\n",
      "0  communities  Ridge  0.364518\n",
      "1  communities  Ridge  0.435435\n",
      "2  communities  Ridge  0.356309\n",
      "           data      method criteria   K  Consistency  Accuracy\n",
      "0   communities  Coef_Ridge      RBO   1        1.000     0.385\n",
      "1   communities  Coef_Ridge      RBO   2        0.875     0.385\n",
      "2   communities  Coef_Ridge      RBO   3        0.806     0.385\n",
      "3   communities  Coef_Ridge      RBO   4        0.792     0.385\n",
      "4   communities  Coef_Ridge      RBO   5        0.753     0.385\n",
      "5   communities  Coef_Ridge      RBO   6        0.725     0.385\n",
      "6   communities  Coef_Ridge      RBO   7        0.713     0.385\n",
      "7   communities  Coef_Ridge      RBO   8        0.702     0.385\n",
      "8   communities  Coef_Ridge      RBO   9        0.698     0.385\n",
      "9   communities  Coef_Ridge      RBO  10        0.698     0.385\n",
      "10  communities  Coef_Ridge      RBO  11        0.697     0.385\n",
      "11  communities  Coef_Ridge      RBO  12        0.698     0.385\n",
      "12  communities  Coef_Ridge      RBO  13        0.695     0.385\n",
      "13  communities  Coef_Ridge      RBO  14        0.691     0.385\n",
      "14  communities  Coef_Ridge      RBO  15        0.685     0.385\n",
      "15  communities  Coef_Ridge      RBO  16        0.679     0.385\n",
      "16  communities  Coef_Ridge      RBO  17        0.675     0.385\n",
      "17  communities  Coef_Ridge      RBO  18        0.672     0.385\n",
      "18  communities  Coef_Ridge      RBO  19        0.670     0.385\n",
      "19  communities  Coef_Ridge      RBO  20        0.669     0.385\n",
      "20  communities  Coef_Ridge      RBO  21        0.669     0.385\n",
      "21  communities  Coef_Ridge      RBO  22        0.670     0.385\n",
      "22  communities  Coef_Ridge      RBO  23        0.673     0.385\n",
      "23  communities  Coef_Ridge      RBO  24        0.675     0.385\n",
      "24  communities  Coef_Ridge      RBO  25        0.676     0.385\n",
      "25  communities  Coef_Ridge      RBO  26        0.678     0.385\n",
      "26  communities  Coef_Ridge      RBO  27        0.680     0.385\n",
      "27  communities  Coef_Ridge      RBO  28        0.682     0.385\n",
      "28  communities  Coef_Ridge      RBO  29        0.685     0.385\n",
      "29  communities  Coef_Ridge      RBO  30        0.687     0.385\n",
      "30  communities  Coef_Ridge  Jaccard   1        1.000     0.385\n",
      "31  communities  Coef_Ridge  Jaccard   2        0.667     0.385\n",
      "32  communities  Coef_Ridge  Jaccard   3        0.500     0.385\n",
      "33  communities  Coef_Ridge  Jaccard   4        0.667     0.385\n",
      "34  communities  Coef_Ridge  Jaccard   5        0.458     0.385\n",
      "35  communities  Coef_Ridge  Jaccard   6        0.417     0.385\n",
      "36  communities  Coef_Ridge  Jaccard   7        0.511     0.385\n",
      "37  communities  Coef_Ridge  Jaccard   8        0.504     0.385\n",
      "38  communities  Coef_Ridge  Jaccard   9        0.543     0.385\n",
      "39  communities  Coef_Ridge  Jaccard  10        0.576     0.385\n",
      "40  communities  Coef_Ridge  Jaccard  11        0.534     0.385\n",
      "41  communities  Coef_Ridge  Jaccard  12        0.590     0.385\n",
      "42  communities  Coef_Ridge  Jaccard  13        0.517     0.385\n",
      "43  communities  Coef_Ridge  Jaccard  14        0.511     0.385\n",
      "44  communities  Coef_Ridge  Jaccard  15        0.458     0.385\n",
      "45  communities  Coef_Ridge  Jaccard  16        0.440     0.385\n",
      "46  communities  Coef_Ridge  Jaccard  17        0.480     0.385\n",
      "47  communities  Coef_Ridge  Jaccard  18        0.461     0.385\n",
      "48  communities  Coef_Ridge  Jaccard  19        0.470     0.385\n",
      "49  communities  Coef_Ridge  Jaccard  20        0.490     0.385\n",
      "50  communities  Coef_Ridge  Jaccard  21        0.508     0.385\n",
      "51  communities  Coef_Ridge  Jaccard  22        0.548     0.385\n",
      "52  communities  Coef_Ridge  Jaccard  23        0.588     0.385\n",
      "53  communities  Coef_Ridge  Jaccard  24        0.550     0.385\n",
      "54  communities  Coef_Ridge  Jaccard  25        0.542     0.385\n",
      "55  communities  Coef_Ridge  Jaccard  26        0.577     0.385\n",
      "56  communities  Coef_Ridge  Jaccard  27        0.588     0.385\n",
      "57  communities  Coef_Ridge  Jaccard  28        0.578     0.385\n",
      "58  communities  Coef_Ridge  Jaccard  29        0.612     0.385\n",
      "59  communities  Coef_Ridge  Jaccard  30        0.623     0.385\n",
      "          data  model   Entropy    Purity\n",
      "0  communities  Ridge  0.162327  0.852243\n"
     ]
    }
   ],
   "source": [
    "model_reg.get_consistency(data_name='communities', estimator_name='Ridge',impotance_func_name='Coef')\n",
    "print(model_reg.accuracy)\n",
    "print(model_reg.consistency)\n",
    "print(model_reg.prediction_consistency)\n",
    "\n",
    "## model_reg.consistency.to_csv('consis_test_fi_reg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2cbfa8",
   "metadata": {},
   "source": [
    "#### 1.1.2. Tree-base model\n",
    "Here we aim to evaluate the interpretation reliability of random forest, using the ``feature_impoReg``function.. We use ``RandomForestRegressor()`` from ``sklearn`` as our estimator. By setting ``importance_func=None``, the default feature importance ``feature_importances_`` of the ``RandomForestRegressor()`` function will be used to evaluate feature importance. \n",
    "All other settings are the same as linear regression in 1.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628a2df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use feature_importances_ as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use feature_importances_ as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use feature_importances_ as feature importance \n",
      "Importance Function is  FI_RF\n",
      "          data model  Accuracy\n",
      "0  communities    RF  0.346505\n",
      "1  communities    RF  0.400400\n",
      "2  communities    RF  0.354550\n",
      "           data method criteria   K  Consistency  Accuracy\n",
      "0   communities  FI_RF      RBO   1        1.000     0.367\n",
      "1   communities  FI_RF      RBO   2        1.000     0.367\n",
      "2   communities  FI_RF      RBO   3        1.000     0.367\n",
      "3   communities  FI_RF      RBO   4        0.969     0.367\n",
      "4   communities  FI_RF      RBO   5        0.935     0.367\n",
      "5   communities  FI_RF      RBO   6        0.932     0.367\n",
      "6   communities  FI_RF      RBO   7        0.911     0.367\n",
      "7   communities  FI_RF      RBO   8        0.891     0.367\n",
      "8   communities  FI_RF      RBO   9        0.872     0.367\n",
      "9   communities  FI_RF      RBO  10        0.865     0.367\n",
      "10  communities  FI_RF      RBO  11        0.857     0.367\n",
      "11  communities  FI_RF      RBO  12        0.851     0.367\n",
      "12  communities  FI_RF      RBO  13        0.842     0.367\n",
      "13  communities  FI_RF      RBO  14        0.835     0.367\n",
      "14  communities  FI_RF      RBO  15        0.826     0.367\n",
      "15  communities  FI_RF      RBO  16        0.816     0.367\n",
      "16  communities  FI_RF      RBO  17        0.806     0.367\n",
      "17  communities  FI_RF      RBO  18        0.796     0.367\n",
      "18  communities  FI_RF      RBO  19        0.789     0.367\n",
      "19  communities  FI_RF      RBO  20        0.783     0.367\n",
      "20  communities  FI_RF      RBO  21        0.781     0.367\n",
      "21  communities  FI_RF      RBO  22        0.782     0.367\n",
      "22  communities  FI_RF      RBO  23        0.783     0.367\n",
      "23  communities  FI_RF      RBO  24        0.783     0.367\n",
      "24  communities  FI_RF      RBO  25        0.783     0.367\n",
      "25  communities  FI_RF      RBO  26        0.783     0.367\n",
      "26  communities  FI_RF      RBO  27        0.784     0.367\n",
      "27  communities  FI_RF      RBO  28        0.784     0.367\n",
      "28  communities  FI_RF      RBO  29        0.784     0.367\n",
      "29  communities  FI_RF      RBO  30        0.784     0.367\n",
      "30  communities  FI_RF  Jaccard   1        1.000     0.367\n",
      "31  communities  FI_RF  Jaccard   2        1.000     0.367\n",
      "32  communities  FI_RF  Jaccard   3        1.000     0.367\n",
      "33  communities  FI_RF  Jaccard   4        0.800     0.367\n",
      "34  communities  FI_RF  Jaccard   5        0.667     0.367\n",
      "35  communities  FI_RF  Jaccard   6        0.857     0.367\n",
      "36  communities  FI_RF  Jaccard   7        0.653     0.367\n",
      "37  communities  FI_RF  Jaccard   8        0.600     0.367\n",
      "38  communities  FI_RF  Jaccard   9        0.568     0.367\n",
      "39  communities  FI_RF  Jaccard  10        0.667     0.367\n",
      "40  communities  FI_RF  Jaccard  11        0.632     0.367\n",
      "41  communities  FI_RF  Jaccard  12        0.657     0.367\n",
      "42  communities  FI_RF  Jaccard  13        0.577     0.367\n",
      "43  communities  FI_RF  Jaccard  14        0.601     0.367\n",
      "44  communities  FI_RF  Jaccard  15        0.539     0.367\n",
      "45  communities  FI_RF  Jaccard  16        0.489     0.367\n",
      "46  communities  FI_RF  Jaccard  17        0.478     0.367\n",
      "47  communities  FI_RF  Jaccard  18        0.470     0.367\n",
      "48  communities  FI_RF  Jaccard  19        0.491     0.367\n",
      "49  communities  FI_RF  Jaccard  20        0.510     0.367\n",
      "50  communities  FI_RF  Jaccard  21        0.585     0.367\n",
      "51  communities  FI_RF  Jaccard  22        0.661     0.367\n",
      "52  communities  FI_RF  Jaccard  23        0.678     0.367\n",
      "53  communities  FI_RF  Jaccard  24        0.663     0.367\n",
      "54  communities  FI_RF  Jaccard  25        0.643     0.367\n",
      "55  communities  FI_RF  Jaccard  26        0.661     0.367\n",
      "56  communities  FI_RF  Jaccard  27        0.665     0.367\n",
      "57  communities  FI_RF  Jaccard  28        0.653     0.367\n",
      "58  communities  FI_RF  Jaccard  29        0.663     0.367\n",
      "59  communities  FI_RF  Jaccard  30        0.626     0.367\n",
      "          data model   Entropy    Purity\n",
      "0  communities    RF  0.162327  0.852243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "estimator=RandomForestRegressor()\n",
    "importance_func=None\n",
    "\n",
    "\n",
    "model_reg_tree=imlreliability.feature_importance.feature_impoReg(data_reg,estimator, \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_tree.fit()\n",
    "model_reg_tree.consistency(data_name='communities', estimator_name='RF',impotance_func_name='FI')\n",
    "print(model_reg_tree.accuracy)\n",
    "print(model_reg_tree.consistency)\n",
    "print(model_reg_tree.prediction_consistency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8dcc1e",
   "metadata": {},
   "source": [
    "### 1.2. Model agnostic \n",
    "For model agnostic methods to measure feature importance, we provide built-in importance functions from package shap and perumutation function from sklearn.inspection. The imlreliability also support elf-defined importance function, with three argument: ``(fitted model, training x, training y)``, and 1 output importance score in forms of list or array:\n",
    "\n",
    "``importance_func(self.fitted,x_train, y_train)``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bad43b",
   "metadata": {},
   "source": [
    "#### 1.2.1. Permutation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-specific",
   "metadata": {},
   "source": [
    "##### 1.2.1.1. Random Forest + Permutation\n",
    "Here we use random forest to consturct the prediction model using the ``feature_impoReg``function, and permutation as the post-hoc method to measure the feature importance, by setting ``importance_func=permutation_importance``. All other settings are the same as linear regression in 1.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06725fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "1\n",
      "Iter:  1\n",
      "2\n",
      "Iter:  2\n",
      "Importance Function is  Permutation_RF\n",
      "          data model  Accuracy\n",
      "0  communities    RF  0.347237\n",
      "1  communities    RF  0.398645\n",
      "2  communities    RF  0.361277\n",
      "           data          method criteria   K  Consistency  Accuracy\n",
      "0   communities  Permutation_RF      RBO   1        1.000     0.369\n",
      "1   communities  Permutation_RF      RBO   2        1.000     0.369\n",
      "2   communities  Permutation_RF      RBO   3        1.000     0.369\n",
      "3   communities  Permutation_RF      RBO   4        0.938     0.369\n",
      "4   communities  Permutation_RF      RBO   5        0.950     0.369\n",
      "5   communities  Permutation_RF      RBO   6        0.944     0.369\n",
      "6   communities  Permutation_RF      RBO   7        0.932     0.369\n",
      "7   communities  Permutation_RF      RBO   8        0.909     0.369\n",
      "8   communities  Permutation_RF      RBO   9        0.895     0.369\n",
      "9   communities  Permutation_RF      RBO  10        0.875     0.369\n",
      "10  communities  Permutation_RF      RBO  11        0.858     0.369\n",
      "11  communities  Permutation_RF      RBO  12        0.845     0.369\n",
      "12  communities  Permutation_RF      RBO  13        0.836     0.369\n",
      "13  communities  Permutation_RF      RBO  14        0.830     0.369\n",
      "14  communities  Permutation_RF      RBO  15        0.828     0.369\n",
      "15  communities  Permutation_RF      RBO  16        0.827     0.369\n",
      "16  communities  Permutation_RF      RBO  17        0.827     0.369\n",
      "17  communities  Permutation_RF      RBO  18        0.827     0.369\n",
      "18  communities  Permutation_RF      RBO  19        0.827     0.369\n",
      "19  communities  Permutation_RF      RBO  20        0.827     0.369\n",
      "20  communities  Permutation_RF      RBO  21        0.826     0.369\n",
      "21  communities  Permutation_RF      RBO  22        0.824     0.369\n",
      "22  communities  Permutation_RF      RBO  23        0.823     0.369\n",
      "23  communities  Permutation_RF      RBO  24        0.822     0.369\n",
      "24  communities  Permutation_RF      RBO  25        0.821     0.369\n",
      "25  communities  Permutation_RF      RBO  26        0.821     0.369\n",
      "26  communities  Permutation_RF      RBO  27        0.820     0.369\n",
      "27  communities  Permutation_RF      RBO  28        0.819     0.369\n",
      "28  communities  Permutation_RF      RBO  29        0.818     0.369\n",
      "29  communities  Permutation_RF      RBO  30        0.816     0.369\n",
      "30  communities  Permutation_RF  Jaccard   1        1.000     0.369\n",
      "31  communities  Permutation_RF  Jaccard   2        1.000     0.369\n",
      "32  communities  Permutation_RF  Jaccard   3        1.000     0.369\n",
      "33  communities  Permutation_RF  Jaccard   4        0.600     0.369\n",
      "34  communities  Permutation_RF  Jaccard   5        1.000     0.369\n",
      "35  communities  Permutation_RF  Jaccard   6        0.857     0.369\n",
      "36  communities  Permutation_RF  Jaccard   7        0.750     0.369\n",
      "37  communities  Permutation_RF  Jaccard   8        0.600     0.369\n",
      "38  communities  Permutation_RF  Jaccard   9        0.636     0.369\n",
      "39  communities  Permutation_RF  Jaccard  10        0.538     0.369\n",
      "40  communities  Permutation_RF  Jaccard  11        0.519     0.369\n",
      "41  communities  Permutation_RF  Jaccard  12        0.550     0.369\n",
      "42  communities  Permutation_RF  Jaccard  13        0.577     0.369\n",
      "43  communities  Permutation_RF  Jaccard  14        0.601     0.369\n",
      "44  communities  Permutation_RF  Jaccard  15        0.667     0.369\n",
      "45  communities  Permutation_RF  Jaccard  16        0.684     0.369\n",
      "46  communities  Permutation_RF  Jaccard  17        0.700     0.369\n",
      "47  communities  Permutation_RF  Jaccard  18        0.714     0.369\n",
      "48  communities  Permutation_RF  Jaccard  19        0.690     0.369\n",
      "49  communities  Permutation_RF  Jaccard  20        0.703     0.369\n",
      "50  communities  Permutation_RF  Jaccard  21        0.683     0.369\n",
      "51  communities  Permutation_RF  Jaccard  22        0.666     0.369\n",
      "52  communities  Permutation_RF  Jaccard  23        0.645     0.369\n",
      "53  communities  Permutation_RF  Jaccard  24        0.685     0.369\n",
      "54  communities  Permutation_RF  Jaccard  25        0.669     0.369\n",
      "55  communities  Permutation_RF  Jaccard  26        0.679     0.369\n",
      "56  communities  Permutation_RF  Jaccard  27        0.665     0.369\n",
      "57  communities  Permutation_RF  Jaccard  28        0.653     0.369\n",
      "58  communities  Permutation_RF  Jaccard  29        0.663     0.369\n",
      "59  communities  Permutation_RF  Jaccard  30        0.626     0.369\n",
      "          data model   Entropy    Purity\n",
      "0  communities    RF  0.162327  0.852243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "estimator=RandomForestRegressor()\n",
    "importance_func = permutation_importance ## change the importance function to be permutation \n",
    "\n",
    "\n",
    "model_reg_tree_per=imlreliability.feature_importance.feature_impoReg(data_reg,estimator, \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_tree_per.fit()\n",
    "model_reg_tree_per.consistency(data_name='communities', estimator_name='RF',impotance_func_name='Permutation')\n",
    "print(model_reg_tree_per.accuracy)\n",
    "print(model_reg_tree_per.consistency)\n",
    "print(model_reg_tree_per.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-probability",
   "metadata": {},
   "source": [
    "##### 1.2.1.2. MLP + Permutation\n",
    "Here we construct a MLP model with two hidden layers as the prediction model, and permutation as the post-hoc method to measure the feature importance, by setting ``importance_func=permutation_importance``. Note that here we use the ``feature_impoReg_MLP`` function for MLP-based techniques. All other settings are the same as linear regression in 1.1.1. \n",
    "\n",
    "A two-layer default MLP will be computed if ``estimator = None``. We also support user-defined MLP models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "simple-lunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  0\n",
      "WARNING:tensorflow:From /Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "['eli5', 'sklearn', 'permutation_importance']\n",
      "598/598 [==============================] - 0s 107us/sample - loss: 0.4576\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4596\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4799\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4641\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 42us/sample - loss: 0.4596\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4595\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4580\n",
      "598/598 [==============================] - 0s 78us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 44us/sample - loss: 0.4625\n",
      "598/598 [==============================] - 0s 52us/sample - loss: 0.4603\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4542\n",
      "598/598 [==============================] - 0s 49us/sample - loss: 0.4554\n",
      "598/598 [==============================] - 0s 50us/sample - loss: 0.4608\n",
      "598/598 [==============================] - 0s 50us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4581\n",
      "598/598 [==============================] - 0s 42us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 48us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 51us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4546\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4576\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4567\n",
      "598/598 [==============================] - 0s 47us/sample - loss: 0.4582\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4546\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4665\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4530\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4543\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4533\n",
      "598/598 [==============================] - 0s 74us/sample - loss: 0.4531\n",
      "598/598 [==============================] - 0s 74us/sample - loss: 0.4588\n",
      "598/598 [==============================] - 0s 59us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 126us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 79us/sample - loss: 0.4550\n",
      "598/598 [==============================] - 0s 56us/sample - loss: 0.4564\n",
      "598/598 [==============================] - 0s 57us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 60us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 42us/sample - loss: 0.4544\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.4587\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4556\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.4553\n",
      "598/598 [==============================] - 0s 45us/sample - loss: 0.4558\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4619\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4670\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4645\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4564\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4564\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4531\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4536\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4554\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4591\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4586\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4556\n",
      "598/598 [==============================] - 0s 44us/sample - loss: 0.4549\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.4541\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.4549\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4603\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4597\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4534\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 45us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 45us/sample - loss: 0.4564\n",
      "598/598 [==============================] - 0s 55us/sample - loss: 0.4554\n",
      "598/598 [==============================] - 0s 93us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4539\n",
      "598/598 [==============================] - 0s 50us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 44us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.4564\n",
      "598/598 [==============================] - 0s 55us/sample - loss: 0.4595\n",
      "598/598 [==============================] - 0s 52us/sample - loss: 0.4586\n",
      "598/598 [==============================] - 0s 58us/sample - loss: 0.4584\n",
      "598/598 [==============================] - 0s 59us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 50us/sample - loss: 0.4594\n",
      "598/598 [==============================] - 0s 59us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 47us/sample - loss: 0.4611\n",
      "598/598 [==============================] - 0s 55us/sample - loss: 0.4635\n",
      "598/598 [==============================] - 0s 42us/sample - loss: 0.4581\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.4576\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4588\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4587\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4591\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4608\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4567\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4686\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4661\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4589\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4594\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4581\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4583\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4625\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4629\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4547\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4545\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4582\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4561\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4590\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4556\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4547\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4564\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4586\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4559\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4615\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4553\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4526\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 47us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4584\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4582\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 44us/sample - loss: 0.4547\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4563\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4592\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4599\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4585\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4580\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4625\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4563\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4611\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4564\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4656\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4640\n",
      "598/598 [==============================] - 0s 56us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 65us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 57us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4516\n",
      "598/598 [==============================] - 0s 61us/sample - loss: 0.4536\n",
      "598/598 [==============================] - 0s 56us/sample - loss: 0.4562\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4585\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4587\n",
      "598/598 [==============================] - 0s 96us/sample - loss: 0.4554\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4582\n",
      "598/598 [==============================] - 0s 45us/sample - loss: 0.4585\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4586\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4580\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4532\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.4567\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4562\n",
      "598/598 [==============================] - 0s 45us/sample - loss: 0.4605\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4598\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4561\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4567\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4558\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4543\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4605\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4591\n",
      "598/598 [==============================] - 0s 56us/sample - loss: 0.4586\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4598\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4582\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4613\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4611\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4580\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 53us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4587\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4593\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4565\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4592\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4608\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 48us/sample - loss: 0.4796\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4607\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4596\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4596\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.4584\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4646\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4615\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4561\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4545\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4608\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4543\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4596\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4582\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4537\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4562\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4585\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4551\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.4649\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4564\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4502\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4545\n",
      "598/598 [==============================] - 0s 48us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4507\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4559\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4584\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4567\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4549\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4551\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4590\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4586\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4608\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4589\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4646\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4567\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4646\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4664\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4563\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4518\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4546\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4550\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4585\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4595\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4565\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4557\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4552\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4543\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4602\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4543\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4584\n",
      "598/598 [==============================] - 0s 64us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4553\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4554\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4548\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4556\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4599\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4583\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4589\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4597\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4600\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4619\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4595\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4584\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4592\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4583\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4594\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4593\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4752\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4609\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4601\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4599\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4619\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4555\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4606\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4542\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4595\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4557\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4558\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4559\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4581\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4559\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4650\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4563\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4554\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4563\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4534\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.4581\n",
      "598/598 [==============================] - 0s 49us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 73us/sample - loss: 0.4576\n",
      "598/598 [==============================] - 0s 50us/sample - loss: 0.4567\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 45us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4526\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4599\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4596\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4614\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4591\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4582\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4647\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4632\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4565\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4538\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4544\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4576\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4565\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4581\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4589\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4576\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4558\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4584\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4542\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4536\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4600\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4539\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4540\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4522\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4558\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4551\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4592\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4589\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4583\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4583\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4585\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4610\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4638\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 112us/sample - loss: 0.4583\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4576\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4614\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4552\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4604\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4583\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4593\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4773\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4592\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4574\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4595\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4603\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4581\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4643\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4603\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.512 - 0s 27us/sample - loss: 0.4546\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4612\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4567\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4598\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4530\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4551\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4562\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4585\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4545\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4666\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4510\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4541\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4548\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4541\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4588\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4566\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4559\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4579\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4588\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4580\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4599\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4564\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4583\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4613\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4593\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4670\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4642\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 19us/sample - loss: 0.4565\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4567\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4522\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4550\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4565\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4573\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4584\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4639\n",
      "598/598 [==============================] - 0s 19us/sample - loss: 0.4537\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4536\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4604\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4558\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4553\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4577\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4584\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4562\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4533\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4581\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4575\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4604\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4593\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4586\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4641\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4644\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4583\n",
      "598/598 [==============================] - 0s 44us/sample - loss: 0.4594\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4581\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4569\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4605\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4594\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4578\n",
      "598/598 [==============================] - 0s 144us/sample - loss: 0.4764\n",
      "Iter:  1\n",
      "['eli5', 'sklearn', 'permutation_importance']\n",
      "598/598 [==============================] - 0s 116us/sample - loss: 0.5383\n",
      "598/598 [==============================] - 0s 63us/sample - loss: 0.5397\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.5474\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5465\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5393\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5368\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5369\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.5413\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.5422\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.5339\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5360\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5412\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5405\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5363\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5339\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5310\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5385\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.5347\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5376\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5321\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5410\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5364\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5355\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5366\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5381\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5363\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5385\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5370\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.5394\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5360\n",
      "598/598 [==============================] - 0s 50us/sample - loss: 0.5417\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5387\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.5400\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5408\n",
      "598/598 [==============================] - 0s 44us/sample - loss: 0.5433\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.5381\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5399\n",
      "598/598 [==============================] - 0s 51us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.5362\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.5400\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5469\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5410\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5311\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.5349\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.5392\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5369\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5369\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5383\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5419\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5369\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5408\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.5394\n",
      "598/598 [==============================] - 0s 164us/sample - loss: 0.5350\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5351\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5314\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5392\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5324\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5365\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5375\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5322\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5377\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5388\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5324\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5397\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5368\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5344\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5366\n",
      "598/598 [==============================] - 0s 81us/sample - loss: 0.5352\n",
      "598/598 [==============================] - 0s 44us/sample - loss: 0.5369\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5338\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5403\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5405\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.5397\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5400\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5378\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5387\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5403\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5416\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5411\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5481\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5502\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5366\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5398\n",
      "598/598 [==============================] - 0s 92us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5410\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.5413\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5357\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5403\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.5398\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5383\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5345\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5373\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5318\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5340\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5387\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.5351\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.5342\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5404\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5339\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5340\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5344\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5349\n",
      "598/598 [==============================] - 0s 47us/sample - loss: 0.5349\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5378\n",
      "598/598 [==============================] - 0s 48us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5373\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5410\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5365\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5428\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5424\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.5378\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5383\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5348\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5352\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5415\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5465\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5404\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5343\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5344\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5381\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5366\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5367\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5378\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5385\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5403\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5381\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5410\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5344\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5363\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5336\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5350\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5412\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 47us/sample - loss: 0.5280\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5390\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5353\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5395\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5365\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5378\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5359\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5361\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5376\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5338\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.5395\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5387\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5399\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5399\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5385\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5421\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5419\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5385\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5482\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5448\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5387\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5402\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5427\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5341\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5354\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5427\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5353\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5385\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5355\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5373\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5318\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5353\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 91us/sample - loss: 0.5343\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5373\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5377\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5342\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5381\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5335\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5350\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5355\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5383\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5352\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.5354\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5405\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5368\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5392\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5376\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5392\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5414\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5460\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5378\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5406\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5416\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5453\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5329\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5356\n",
      "598/598 [==============================] - 0s 44us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5358\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5368\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5422\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5406\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5365\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.5387\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5327\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5397\n",
      "598/598 [==============================] - 0s 48us/sample - loss: 0.5339\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5361\n",
      "598/598 [==============================] - 0s 78us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 45us/sample - loss: 0.5366\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5315\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.5388\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5390\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.5376\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5402\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5366\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5344\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5365\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5341\n",
      "598/598 [==============================] - 0s 42us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5383\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5417\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5397\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 54us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 57us/sample - loss: 0.5388\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5393\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5390\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5433\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5370\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5397\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5509\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5480\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5369\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5363\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5398\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5413\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5420\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.5350\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.5375\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5394\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5388\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5375\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5338\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5331\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5332\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.5327\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5399\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5324\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5355\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5354\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5370\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5330\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5366\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.5391\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5383\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5368\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5373\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5357\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5411\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5397\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5390\n",
      "598/598 [==============================] - 0s 81us/sample - loss: 0.5399\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5406\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.5376\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5393\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5355\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5420\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5464\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5402\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5329\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5324\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5392\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5355\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5376\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5385\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5406\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5400\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5373\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5407\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5364\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5336\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5337\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5358\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5388\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5364\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5313\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5390\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5388\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5334\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.5381\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5358\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5367\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.5354\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5365\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5340\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5403\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5382\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5393\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5366\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5387\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5408\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5433\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5399\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5399\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5380\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5466\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5516\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5378\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5362\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5367\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5397\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5409\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5437\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5346\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.5412\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5400\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5388\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5326\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5373\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5313\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5346\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5381\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5356\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5377\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5370\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5305\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5402\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.5355\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5347\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5350\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5369\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5338\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5393\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5369\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.5421\n",
      "598/598 [==============================] - 0s 19us/sample - loss: 0.5365\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5404\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5377\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5394\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5394\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5388\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5459\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5426\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5325\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5344\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5385\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5348\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5367\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5401\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.5415\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5384\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.5372\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5383\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5420\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5386\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5353\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5393\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.5344\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5403\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5360\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.5364\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5415\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5364\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5358\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.5379\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.5395\n",
      "598/598 [==============================] - 0s 68us/sample - loss: 0.5390\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5339\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5390\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5368\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5377\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5361\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.5328\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.5373\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5351\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5383\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5387\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5378\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.5407\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5403\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5389\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.5371\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.5374\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5388\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.5364\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.5399\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5396\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.5419\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.5405\n",
      "598/598 [==============================] - 0s 71us/sample - loss: 0.4688\n",
      "Iter:  2\n",
      "['eli5', 'sklearn', 'permutation_importance']\n",
      "598/598 [==============================] - 0s 131us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4498\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4532\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4554\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4487\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4460\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4501\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4523\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4515\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4465\n",
      "598/598 [==============================] - 0s 60us/sample - loss: 0.4465\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4533\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4463\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4440\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4495\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4450\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4463\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4495\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4436\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4537\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4451\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4424\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4457\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4424\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4459\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4479\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4458\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4489\n",
      "598/598 [==============================] - 0s 52us/sample - loss: 0.4485\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.354 - 0s 67us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4463\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.4545\n",
      "598/598 [==============================] - 0s 84us/sample - loss: 0.4522\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4503\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4554\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4561\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4555\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4491\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4457\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4463\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4479\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4479\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4480\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4475\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 45us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4493\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4446\n",
      "598/598 [==============================] - 0s 53us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4641\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4504\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4498\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4456\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4466\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4487\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4461\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4533\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4456\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4467\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4441\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4490\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4516\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4493\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4469\n",
      "598/598 [==============================] - 0s 65us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4487\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4475\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4508\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4496\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4590\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4560\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4455\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4501\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4492\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4512\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4493\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4468\n",
      "598/598 [==============================] - 0s 45us/sample - loss: 0.4446\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4509\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4460\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4475\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4459\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4489\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4451\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4422\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4527\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4436\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4431\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4446\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4449\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4458\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4465\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4502\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4513\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4522\n",
      "598/598 [==============================] - 0s 19us/sample - loss: 0.4495\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4541\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4512\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4460\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4600\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4471\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4568\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4561\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4469\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4468\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4455\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4498\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4502\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4521\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4473\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4463\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4447\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4451\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4467\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4471\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4448\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4460\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4454\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4536\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4501\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4507\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4426\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4432\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4491\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4517\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4466\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4438\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4493\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4469\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4473\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4493\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4471\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4471\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4470\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4490\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4492\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4465\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4499\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4503\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4524\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4532\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4513\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4505\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4533\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4447\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4443\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4454\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4435\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4461\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 76us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4427\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4531\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4446\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4423\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4423\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4425\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4471\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4480\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4490\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4499\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4465\n",
      "598/598 [==============================] - 0s 19us/sample - loss: 0.4493\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4528\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4542\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4465\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4551\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4551\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4466\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4468\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4473\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.364 - 0s 22us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 36us/sample - loss: 0.4493\n",
      "598/598 [==============================] - 0s 38us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4451\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4490\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4450\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4498\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 40us/sample - loss: 0.4461\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4495\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4445\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4595\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4500\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4494\n",
      "598/598 [==============================] - 0s 50us/sample - loss: 0.4473\n",
      "598/598 [==============================] - 0s 43us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4437\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4460\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4487\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4460\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4514\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4459\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4467\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4448\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4490\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4495\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4480\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 54us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 83us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 44us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 60us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4470\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4499\n",
      "598/598 [==============================] - 0s 37us/sample - loss: 0.4479\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4487\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4571\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4570\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4494\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4480\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4499\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 39us/sample - loss: 0.4466\n",
      "598/598 [==============================] - 0s 51us/sample - loss: 0.4517\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4521\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4449\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4461\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4502\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4504\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4441\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4487\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4456\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4497\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4455\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4410\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4499\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4453\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4448\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4469\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4440\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4463\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4468\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4525\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4466\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4517\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598/598 [==============================] - 0s 79us/sample - loss: 0.4466\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4530\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4469\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4572\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4588\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4489\n",
      "598/598 [==============================] - 0s 31us/sample - loss: 0.4465\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4463\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4471\n",
      "598/598 [==============================] - 0s 34us/sample - loss: 0.4459\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4500\n",
      "598/598 [==============================] - 0s 46us/sample - loss: 0.4471\n",
      "598/598 [==============================] - 0s 47us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4495\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4489\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4460\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4489\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4467\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4451\n",
      "598/598 [==============================] - 0s 55us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 76us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4465\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4596\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4498\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4460\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4445\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4430\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4473\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4507\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4449\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4471\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4453\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4493\n",
      "598/598 [==============================] - 0s 41us/sample - loss: 0.4468\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4473\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4492\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4490\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4479\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4470\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4463\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4478\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4490\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4512\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4505\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4482\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4542\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4576\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4487\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4473\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4502\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4489\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4489\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4509\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4518\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4456\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4447\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4536\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4440\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 20us/sample - loss: 0.4454\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4459\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4492\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4458\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4428\n",
      "598/598 [==============================] - 0s 35us/sample - loss: 0.4505\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4433\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4441\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4427\n",
      "598/598 [==============================] - 0s 27us/sample - loss: 0.4469\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4436\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4454\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4480\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4473\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4471\n",
      "598/598 [==============================] - 0s 32us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4505\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4476\n",
      "598/598 [==============================] - 0s 21us/sample - loss: 0.4503\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 33us/sample - loss: 0.4510\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4502\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4467\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4556\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4464\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4468\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4547\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4580\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4487\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4465\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4466\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4458\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4495\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4480\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4490\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4462\n",
      "598/598 [==============================] - ETA: 0s - loss: 0.373 - 0s 25us/sample - loss: 0.4496\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4442\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4489\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4451\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4446\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4451\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4472\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4591\n",
      "598/598 [==============================] - 0s 30us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4500\n",
      "598/598 [==============================] - 0s 29us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 90us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4438\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4463\n",
      "598/598 [==============================] - 0s 28us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4462\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4502\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4459\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4467\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4453\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4490\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4484\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4481\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4477\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4483\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4497\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 22us/sample - loss: 0.4473\n",
      "598/598 [==============================] - 0s 19us/sample - loss: 0.4489\n",
      "598/598 [==============================] - 0s 23us/sample - loss: 0.4488\n",
      "598/598 [==============================] - 0s 26us/sample - loss: 0.4485\n",
      "598/598 [==============================] - 0s 25us/sample - loss: 0.4474\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4486\n",
      "598/598 [==============================] - 0s 24us/sample - loss: 0.4524\n",
      "598/598 [==============================] - 0s 57us/sample - loss: 0.3416\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'feature_impoReg_MLP' object has no attribute 'consistency'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-dbfa87a4d783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 rand_index=1)\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_reg_mlp_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_reg_mlp_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'communities'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'MLP'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimpotance_func_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Permutation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_reg_mlp_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_reg_mlp_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsistency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'feature_impoReg_MLP' object has no attribute 'consistency'"
     ]
    }
   ],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "importance_func =PermutationImportance\n",
    "\n",
    "model_reg_mlp_dl=imlreliability.feature_importance.feature_impoReg_MLP(data_reg,\n",
    "                 importance_func=PermutationImportance,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_mlp_dl.fit()\n",
    "model_reg_mlp_dl.consistency(data_name='communities', estimator_name='MLP',impotance_func_name='Permutation')\n",
    "print(model_reg_mlp_dl.accuracy)\n",
    "print(model_reg_mlp_dl.consistency)\n",
    "print(model_reg_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce05eb",
   "metadata": {},
   "source": [
    "#### 1.2.2. Shapley Value \n",
    "\n",
    "Here we use random forest to consturct the prediction model, and SHAP as the post-hoc method to measure the feature importance, by setting ``importance_func=shap.TreeExplainer``. All other settings are the same as linear regression in 1.1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "covered-ferry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "1\n",
      "Iter:  1\n",
      "2\n",
      "Iter:  2\n",
      "Importance Function is  SHAP_RF\n",
      "          data model  Accuracy\n",
      "0  communities    RF  0.341917\n",
      "1  communities    RF  0.409945\n",
      "2  communities    RF  0.357607\n",
      "           data   method criteria   K  Consistency  Accuracy\n",
      "0   communities  SHAP_RF      RBO   1        1.000      0.37\n",
      "1   communities  SHAP_RF      RBO   2        0.750      0.37\n",
      "2   communities  SHAP_RF      RBO   3        0.722      0.37\n",
      "3   communities  SHAP_RF      RBO   4        0.729      0.37\n",
      "4   communities  SHAP_RF      RBO   5        0.703      0.37\n",
      "5   communities  SHAP_RF      RBO   6        0.697      0.37\n",
      "6   communities  SHAP_RF      RBO   7        0.700      0.37\n",
      "7   communities  SHAP_RF      RBO   8        0.698      0.37\n",
      "8   communities  SHAP_RF      RBO   9        0.688      0.37\n",
      "9   communities  SHAP_RF      RBO  10        0.690      0.37\n",
      "10  communities  SHAP_RF      RBO  11        0.685      0.37\n",
      "11  communities  SHAP_RF      RBO  12        0.676      0.37\n",
      "12  communities  SHAP_RF      RBO  13        0.675      0.37\n",
      "13  communities  SHAP_RF      RBO  14        0.675      0.37\n",
      "14  communities  SHAP_RF      RBO  15        0.672      0.37\n",
      "15  communities  SHAP_RF      RBO  16        0.671      0.37\n",
      "16  communities  SHAP_RF      RBO  17        0.670      0.37\n",
      "17  communities  SHAP_RF      RBO  18        0.666      0.37\n",
      "18  communities  SHAP_RF      RBO  19        0.663      0.37\n",
      "19  communities  SHAP_RF      RBO  20        0.661      0.37\n",
      "20  communities  SHAP_RF      RBO  21        0.659      0.37\n",
      "21  communities  SHAP_RF      RBO  22        0.658      0.37\n",
      "22  communities  SHAP_RF      RBO  23        0.657      0.37\n",
      "23  communities  SHAP_RF      RBO  24        0.655      0.37\n",
      "24  communities  SHAP_RF      RBO  25        0.653      0.37\n",
      "25  communities  SHAP_RF      RBO  26        0.651      0.37\n",
      "26  communities  SHAP_RF      RBO  27        0.649      0.37\n",
      "27  communities  SHAP_RF      RBO  28        0.648      0.37\n",
      "28  communities  SHAP_RF      RBO  29        0.646      0.37\n",
      "29  communities  SHAP_RF      RBO  30        0.645      0.37\n",
      "30  communities  SHAP_RF  Jaccard   1        1.000      0.37\n",
      "31  communities  SHAP_RF  Jaccard   2        0.333      0.37\n",
      "32  communities  SHAP_RF  Jaccard   3        0.500      0.37\n",
      "33  communities  SHAP_RF  Jaccard   4        0.600      0.37\n",
      "34  communities  SHAP_RF  Jaccard   5        0.429      0.37\n",
      "35  communities  SHAP_RF  Jaccard   6        0.500      0.37\n",
      "36  communities  SHAP_RF  Jaccard   7        0.556      0.37\n",
      "37  communities  SHAP_RF  Jaccard   8        0.527      0.37\n",
      "38  communities  SHAP_RF  Jaccard   9        0.442      0.37\n",
      "39  communities  SHAP_RF  Jaccard  10        0.538      0.37\n",
      "40  communities  SHAP_RF  Jaccard  11        0.467      0.37\n",
      "41  communities  SHAP_RF  Jaccard  12        0.412      0.37\n",
      "42  communities  SHAP_RF  Jaccard  13        0.487      0.37\n",
      "43  communities  SHAP_RF  Jaccard  14        0.515      0.37\n",
      "44  communities  SHAP_RF  Jaccard  15        0.464      0.37\n",
      "45  communities  SHAP_RF  Jaccard  16        0.489      0.37\n",
      "46  communities  SHAP_RF  Jaccard  17        0.481      0.37\n",
      "47  communities  SHAP_RF  Jaccard  18        0.442      0.37\n",
      "48  communities  SHAP_RF  Jaccard  19        0.439      0.37\n",
      "49  communities  SHAP_RF  Jaccard  20        0.455      0.37\n",
      "50  communities  SHAP_RF  Jaccard  21        0.450      0.37\n",
      "51  communities  SHAP_RF  Jaccard  22        0.468      0.37\n",
      "52  communities  SHAP_RF  Jaccard  23        0.464      0.37\n",
      "53  communities  SHAP_RF  Jaccard  24        0.436      0.37\n",
      "54  communities  SHAP_RF  Jaccard  25        0.430      0.37\n",
      "55  communities  SHAP_RF  Jaccard  26        0.446      0.37\n",
      "56  communities  SHAP_RF  Jaccard  27        0.422      0.37\n",
      "57  communities  SHAP_RF  Jaccard  28        0.437      0.37\n",
      "58  communities  SHAP_RF  Jaccard  29        0.434      0.37\n",
      "59  communities  SHAP_RF  Jaccard  30        0.448      0.37\n",
      "          data model   Entropy    Purity\n",
      "0  communities    RF  0.162327  0.852243\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "estimator=RandomForestRegressor()\n",
    "importance_func = shap.TreeExplainer ## change the importance function to be SHAP \n",
    "\n",
    "model_reg_tree_shap=imlreliability.feature_importance.feature_impoReg(data_reg,estimator, \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_tree_shap.fit()\n",
    "model_reg_tree_shap.consistency(data_name='communities', estimator_name='RF',impotance_func_name='SHAP')\n",
    "print(model_reg_tree_shap.accuracy)\n",
    "print(model_reg_tree_shap.consistency)\n",
    "print(model_reg_tree_shap.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a523664c",
   "metadata": {},
   "source": [
    "### 1.3. MLP specific models \n",
    "We have built-in functions to run functions from ``deepexplain`` and  ``deeplift`` packages. As well permutation and shapley values. User can either input a function or a string from [\n",
    "                        'zero',\n",
    "                        'saliency',\n",
    "                        'grad*input',\n",
    "                        'intgrad',\n",
    "                        'elrp',\n",
    "                        'deeplift',\n",
    "                        'occlusion',\n",
    "                        'shapley_sampling'] to run deepExplain. \n",
    "Or input strings from ['NonlinearMxtsMode.RevealCancel','NonlinearMxtsMode.GuidedBackprop'...] to run corresponding functions in deeplift. \n",
    "\n",
    "\n",
    "imlreliability package also support self-defined importance function, with three argument: ``(fitted model, training x, training y)``, and 1 output importance score in forms of list or array:``importance_func(model,x_train, y_train)``. \n",
    "\n",
    "And the defined estimator needs to be form of :\n",
    "      \n",
    "```Python\n",
    "def _base_model_regression():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model  \n",
    "```\n",
    "\n",
    "And the trained MLP model is saved as .h5 file. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a78df",
   "metadata": {},
   "source": [
    "#### 1.3.1. Deeplift\n",
    "\n",
    "Here we construct a MLP model with two hidden layers as the prediction model, and deeplift as the post-hoc method to measure the feature importance, by setting ``importance_func='NonlinearMxtsMode.RevealCancel'``. All other settings are the same as linear regression in 1.1. \n",
    "\n",
    "A two-layer default MLP will be computed if ``estimator = None``. We also support user-defined MLP models. Any deeplift.layers functions can be used to measure the feature importance by setting parameter ``importance_func`` in its string form. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981fe9e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  0\n",
      "DeepLift\n",
      "nonlinear_mxts_mode is set to: RevealCancel\n",
      "Computing scores for: NonlinearMxtsMode.RevealCancel\n",
      "598/598 [==============================] - 0s 232us/sample - loss: 0.4724\n",
      "Iter:  1\n",
      "DeepLift\n",
      "nonlinear_mxts_mode is set to: RevealCancel\n",
      "Computing scores for: NonlinearMxtsMode.RevealCancel\n",
      "598/598 [==============================] - 0s 66us/sample - loss: 0.4359\n",
      "Iter:  2\n",
      "DeepLift\n",
      "nonlinear_mxts_mode is set to: RevealCancel\n",
      "Computing scores for: NonlinearMxtsMode.RevealCancel\n",
      "598/598 [==============================] - 0s 58us/sample - loss: 0.3315\n",
      "Importance Function is  DeepLift_MLP\n",
      "          data model  Accuracy\n",
      "0  communities   MLP  0.472432\n",
      "1  communities   MLP  0.435864\n",
      "2  communities   MLP  0.331513\n",
      "           data        method criteria   K  Consistency  Accuracy\n",
      "0   communities  DeepLift_MLP      RBO   1        0.000     0.413\n",
      "1   communities  DeepLift_MLP      RBO   2        0.000     0.413\n",
      "2   communities  DeepLift_MLP      RBO   3        0.000     0.413\n",
      "3   communities  DeepLift_MLP      RBO   4        0.000     0.413\n",
      "4   communities  DeepLift_MLP      RBO   5        0.000     0.413\n",
      "5   communities  DeepLift_MLP      RBO   6        0.014     0.413\n",
      "6   communities  DeepLift_MLP      RBO   7        0.032     0.413\n",
      "7   communities  DeepLift_MLP      RBO   8        0.044     0.413\n",
      "8   communities  DeepLift_MLP      RBO   9        0.051     0.413\n",
      "9   communities  DeepLift_MLP      RBO  10        0.061     0.413\n",
      "10  communities  DeepLift_MLP      RBO  11        0.080     0.413\n",
      "11  communities  DeepLift_MLP      RBO  12        0.095     0.413\n",
      "12  communities  DeepLift_MLP      RBO  13        0.105     0.413\n",
      "13  communities  DeepLift_MLP      RBO  14        0.115     0.413\n",
      "14  communities  DeepLift_MLP      RBO  15        0.125     0.413\n",
      "15  communities  DeepLift_MLP      RBO  16        0.137     0.413\n",
      "16  communities  DeepLift_MLP      RBO  17        0.150     0.413\n",
      "17  communities  DeepLift_MLP      RBO  18        0.160     0.413\n",
      "18  communities  DeepLift_MLP      RBO  19        0.170     0.413\n",
      "19  communities  DeepLift_MLP      RBO  20        0.177     0.413\n",
      "20  communities  DeepLift_MLP      RBO  21        0.185     0.413\n",
      "21  communities  DeepLift_MLP      RBO  22        0.192     0.413\n",
      "22  communities  DeepLift_MLP      RBO  23        0.199     0.413\n",
      "23  communities  DeepLift_MLP      RBO  24        0.206     0.413\n",
      "24  communities  DeepLift_MLP      RBO  25        0.212     0.413\n",
      "25  communities  DeepLift_MLP      RBO  26        0.219     0.413\n",
      "26  communities  DeepLift_MLP      RBO  27        0.225     0.413\n",
      "27  communities  DeepLift_MLP      RBO  28        0.231     0.413\n",
      "28  communities  DeepLift_MLP      RBO  29        0.237     0.413\n",
      "29  communities  DeepLift_MLP      RBO  30        0.242     0.413\n",
      "30  communities  DeepLift_MLP  Jaccard   1        0.000     0.413\n",
      "31  communities  DeepLift_MLP  Jaccard   2        0.000     0.413\n",
      "32  communities  DeepLift_MLP  Jaccard   3        0.000     0.413\n",
      "33  communities  DeepLift_MLP  Jaccard   4        0.000     0.413\n",
      "34  communities  DeepLift_MLP  Jaccard   5        0.000     0.413\n",
      "35  communities  DeepLift_MLP  Jaccard   6        0.045     0.413\n",
      "36  communities  DeepLift_MLP  Jaccard   7        0.077     0.413\n",
      "37  communities  DeepLift_MLP  Jaccard   8        0.067     0.413\n",
      "38  communities  DeepLift_MLP  Jaccard   9        0.059     0.413\n",
      "39  communities  DeepLift_MLP  Jaccard  10        0.082     0.413\n",
      "40  communities  DeepLift_MLP  Jaccard  11        0.158     0.413\n",
      "41  communities  DeepLift_MLP  Jaccard  12        0.143     0.413\n",
      "42  communities  DeepLift_MLP  Jaccard  13        0.130     0.413\n",
      "43  communities  DeepLift_MLP  Jaccard  14        0.143     0.413\n",
      "44  communities  DeepLift_MLP  Jaccard  15        0.156     0.413\n",
      "45  communities  DeepLift_MLP  Jaccard  16        0.187     0.413\n",
      "46  communities  DeepLift_MLP  Jaccard  17        0.214     0.413\n",
      "47  communities  DeepLift_MLP  Jaccard  18        0.200     0.413\n",
      "48  communities  DeepLift_MLP  Jaccard  19        0.207     0.413\n",
      "49  communities  DeepLift_MLP  Jaccard  20        0.194     0.413\n",
      "50  communities  DeepLift_MLP  Jaccard  21        0.200     0.413\n",
      "51  communities  DeepLift_MLP  Jaccard  22        0.206     0.413\n",
      "52  communities  DeepLift_MLP  Jaccard  23        0.211     0.413\n",
      "53  communities  DeepLift_MLP  Jaccard  24        0.231     0.413\n",
      "54  communities  DeepLift_MLP  Jaccard  25        0.220     0.413\n",
      "55  communities  DeepLift_MLP  Jaccard  26        0.238     0.413\n",
      "56  communities  DeepLift_MLP  Jaccard  27        0.242     0.413\n",
      "57  communities  DeepLift_MLP  Jaccard  28        0.244     0.413\n",
      "58  communities  DeepLift_MLP  Jaccard  29        0.247     0.413\n",
      "59  communities  DeepLift_MLP  Jaccard  30        0.250     0.413\n",
      "          data model   Entropy    Purity\n",
      "0  communities   MLP  0.162327  0.852243\n"
     ]
    }
   ],
   "source": [
    "from deeplift.layers import NonlinearMxtsMode\n",
    "import deeplift\n",
    "importance_func = 'NonlinearMxtsMode.RevealCancel'\n",
    "\n",
    "model_reg_mlp_dl=imlreliability.feature_importance.feature_impoReg_MLP(data_reg,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_mlp_dl.fit()\n",
    "model_reg_mlp_dl.consistency(data_name='communities', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_reg_mlp_dl.accuracy)\n",
    "print(model_reg_mlp_dl.consistency)\n",
    "print(model_reg_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1da12",
   "metadata": {},
   "source": [
    "#### 1.3.2. DeepExplain\n",
    "Here we construct a MLP model with two hidden layers as the prediction model, and epsilon-LRP as the post-hoc method to measure the feature importance, by setting ``importance_func='elrp'``. All other settings are the same as linear regression in 1.1. \n",
    "\n",
    "A two-layer default MLP will be computed if ``estimator = None``. We also support user-defined MLP models. Any DeepExplain function can be used to measure the feature importance by setting parameter ``importance_func`` in its string form. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99195e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Iter:  0\n",
      "WARNING:tensorflow:From /Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "DeepExplain\n",
      "598/598 [==============================] - 0s 119us/sample - loss: 0.4488\n",
      "Iter:  1\n",
      "DeepExplain\n",
      "598/598 [==============================] - 0s 51us/sample - loss: 0.4519\n",
      "Iter:  2\n",
      "DeepExplain\n",
      "598/598 [==============================] - 0s 59us/sample - loss: 0.3333\n",
      "Importance Function is  elrp_MLP\n",
      "          data model  Accuracy\n",
      "0  communities   MLP  0.448769\n",
      "1  communities   MLP  0.451854\n",
      "2  communities   MLP  0.333314\n",
      "           data    method criteria   K  Consistency  Accuracy\n",
      "0   communities  elrp_MLP      RBO   1        1.000     0.411\n",
      "1   communities  elrp_MLP      RBO   2        0.750     0.411\n",
      "2   communities  elrp_MLP      RBO   3        0.722     0.411\n",
      "3   communities  elrp_MLP      RBO   4        0.729     0.411\n",
      "4   communities  elrp_MLP      RBO   5        0.743     0.411\n",
      "5   communities  elrp_MLP      RBO   6        0.744     0.411\n",
      "6   communities  elrp_MLP      RBO   7        0.740     0.411\n",
      "7   communities  elrp_MLP      RBO   8        0.757     0.411\n",
      "8   communities  elrp_MLP      RBO   9        0.759     0.411\n",
      "9   communities  elrp_MLP      RBO  10        0.768     0.411\n",
      "10  communities  elrp_MLP      RBO  11        0.777     0.411\n",
      "11  communities  elrp_MLP      RBO  12        0.782     0.411\n",
      "12  communities  elrp_MLP      RBO  13        0.790     0.411\n",
      "13  communities  elrp_MLP      RBO  14        0.794     0.411\n",
      "14  communities  elrp_MLP      RBO  15        0.795     0.411\n",
      "15  communities  elrp_MLP      RBO  16        0.792     0.411\n",
      "16  communities  elrp_MLP      RBO  17        0.794     0.411\n",
      "17  communities  elrp_MLP      RBO  18        0.799     0.411\n",
      "18  communities  elrp_MLP      RBO  19        0.807     0.411\n",
      "19  communities  elrp_MLP      RBO  20        0.812     0.411\n",
      "20  communities  elrp_MLP      RBO  21        0.815     0.411\n",
      "21  communities  elrp_MLP      RBO  22        0.818     0.411\n",
      "22  communities  elrp_MLP      RBO  23        0.819     0.411\n",
      "23  communities  elrp_MLP      RBO  24        0.821     0.411\n",
      "24  communities  elrp_MLP      RBO  25        0.822     0.411\n",
      "25  communities  elrp_MLP      RBO  26        0.822     0.411\n",
      "26  communities  elrp_MLP      RBO  27        0.822     0.411\n",
      "27  communities  elrp_MLP      RBO  28        0.823     0.411\n",
      "28  communities  elrp_MLP      RBO  29        0.825     0.411\n",
      "29  communities  elrp_MLP      RBO  30        0.827     0.411\n",
      "30  communities  elrp_MLP  Jaccard   1        1.000     0.411\n",
      "31  communities  elrp_MLP  Jaccard   2        0.333     0.411\n",
      "32  communities  elrp_MLP  Jaccard   3        0.500     0.411\n",
      "33  communities  elrp_MLP  Jaccard   4        0.600     0.411\n",
      "34  communities  elrp_MLP  Jaccard   5        0.667     0.411\n",
      "35  communities  elrp_MLP  Jaccard   6        0.607     0.411\n",
      "36  communities  elrp_MLP  Jaccard   7        0.556     0.411\n",
      "37  communities  elrp_MLP  Jaccard   8        0.778     0.411\n",
      "38  communities  elrp_MLP  Jaccard   9        0.636     0.411\n",
      "39  communities  elrp_MLP  Jaccard  10        0.742     0.411\n",
      "40  communities  elrp_MLP  Jaccard  11        0.763     0.411\n",
      "41  communities  elrp_MLP  Jaccard  12        0.723     0.411\n",
      "42  communities  elrp_MLP  Jaccard  13        0.795     0.411\n",
      "43  communities  elrp_MLP  Jaccard  14        0.750     0.411\n",
      "44  communities  elrp_MLP  Jaccard  15        0.667     0.411\n",
      "45  communities  elrp_MLP  Jaccard  16        0.600     0.411\n",
      "46  communities  elrp_MLP  Jaccard  17        0.700     0.411\n",
      "47  communities  elrp_MLP  Jaccard  18        0.800     0.411\n",
      "48  communities  elrp_MLP  Jaccard  19        0.900     0.411\n",
      "49  communities  elrp_MLP  Jaccard  20        0.818     0.411\n",
      "50  communities  elrp_MLP  Jaccard  21        0.788     0.411\n",
      "51  communities  elrp_MLP  Jaccard  22        0.797     0.411\n",
      "52  communities  elrp_MLP  Jaccard  23        0.736     0.411\n",
      "53  communities  elrp_MLP  Jaccard  24        0.746     0.411\n",
      "54  communities  elrp_MLP  Jaccard  25        0.724     0.411\n",
      "55  communities  elrp_MLP  Jaccard  26        0.705     0.411\n",
      "56  communities  elrp_MLP  Jaccard  27        0.715     0.411\n",
      "57  communities  elrp_MLP  Jaccard  28        0.723     0.411\n",
      "58  communities  elrp_MLP  Jaccard  29        0.785     0.411\n",
      "59  communities  elrp_MLP  Jaccard  30        0.818     0.411\n",
      "          data model   Entropy    Purity\n",
      "0  communities   MLP  0.162327  0.852243\n"
     ]
    }
   ],
   "source": [
    "from deepexplain.tensorflow import DeepExplain\n",
    "importance_func ='elrp'\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_reg_mlp_dl=imlreliability.feature_importance.feature_impoReg_MLP(data_reg,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_mlp_dl.fit()\n",
    "model_reg_mlp_dl.consistency(data_name='communities', estimator_name='MLP',impotance_func_name='elrp')\n",
    "print(model_reg_mlp_dl.accuracy)\n",
    "print(model_reg_mlp_dl.consistency)\n",
    "print(model_reg_mlp_dl.prediction_consistency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-activity",
   "metadata": {},
   "source": [
    "## 2. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-force",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-resolution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
