{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3bbe3b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66faeb56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/alice/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import imlreliability\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9c219",
   "metadata": {},
   "source": [
    "### Dimension Reduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e7ef7",
   "metadata": {},
   "source": [
    "#### Load data\n",
    "We use the WDBC Breast Cancer Wisconsin data as an example for the following sections. The data has 569 observations and 30 feature, and 2 oracle clusters. We scale and normalize the data as pre-processing steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42086510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)\n",
    "data=data.dropna()\n",
    "y=(data[1])\n",
    "x = data.drop(columns=[0,1]).to_numpy()\n",
    "K=len(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-boating",
   "metadata": {},
   "source": [
    "The dimension reduction estimator is assumed to implement the scikit-learn estimator interface.  We propose two data perturbation approaches: \n",
    "\n",
    "    1. noise addition and \n",
    "    2. data spliting. \n",
    "\n",
    "\n",
    "In addition, we measure the reliability of dimension reduction techniques from two aspects: \n",
    "\n",
    "    1. Consistency of clustering results on the reduced dimesion, \n",
    "    2. Consistency of local neighborhood. \n",
    "    \n",
    "We will show examples under each scenario in the following sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086680b0",
   "metadata": {},
   "source": [
    "### 1. Noise Addition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24df053d",
   "metadata": {},
   "source": [
    "###  1.1 Clustering consistency on reducted dimesion\n",
    "\n",
    "We wish to evaluate the interpretation reliability of PCA using the ``PCA()`` function of ``sklearn``. We measure the consistency of K-Means clustering on the first two reduced dimensions (``rank=2``). Here we perturb the data with noise addition by setting ``perturbation = 'noise'``.  We add normal noise with mean 0 and standard deviation 1 by setting ``noise_type='normal'`` and ``sigma=1``. For illustration purpose, we run 3 repeats.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e76b698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  0\n",
      "Iter:  1\n",
      "Iter:  2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "esti=PCA()\n",
    "\n",
    "model = imlreliability.dimension_reduction.dimension_reduction(x,estimator=esti,K=len(set(y)),\n",
    "                 label=y,\n",
    "                 perturbation = 'noise',\n",
    "                rank=2,\n",
    "                 sigma=1,\n",
    "                 noise_type='normal',\n",
    "                 n_repeat=3,\n",
    "                    rand_index=1,\n",
    "                    verbose=True)\n",
    "\n",
    "model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-german",
   "metadata": {},
   "source": [
    "The ``.get_consistency_clustering`` perform clustering on the reduced dimension. Here we use the ``sklearn`` function ``K-Means()`` as an example. A summary pandas dataframe: ``results`` includes model details, clustering accuracy, if the true label is provided, and clusteirng consistency measured by different criterias. \n",
    "\n",
    "The ``results`` pandas dataframe can be downloaded and upload to the dashboard. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-revolution",
   "metadata": {},
   "source": [
    "###### 1.1.1 With true labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cubic-sport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data method perturbation clustering   noise  sigma  rank  \\\n",
      "0  WDBC    PCA        noise         KM  normal      1     2   \n",
      "1  WDBC    PCA        noise         KM  normal      1     2   \n",
      "2  WDBC    PCA        noise         KM  normal      1     2   \n",
      "3  WDBC    PCA        noise         KM  normal      1     2   \n",
      "\n",
      "                criteria  Accuracy  Consistency  \n",
      "0                    ARI  0.321000     0.431333  \n",
      "1  Fowlkes Mallows Score  0.593667     0.578000  \n",
      "2     Mutual Information  0.381667     0.465000  \n",
      "3        V Measure Score  0.383667     0.468000  \n"
     ]
    }
   ],
   "source": [
    "model.get_consistency_clustering('WDBC','PCA',KMeans(n_clusters=4),'KM')\n",
    "print(model.results)\n",
    "\n",
    "# model.results.to_csv('dr_clus_new_km_noise.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-recipient",
   "metadata": {},
   "source": [
    "###### 1.1.2 Without true labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "social-crossing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  0\n",
      "Iter:  1\n",
      "Iter:  2\n",
      "   data method perturbation clustering   noise  sigma  rank  \\\n",
      "0  WDBC    PCA        noise         KM  normal      1     2   \n",
      "1  WDBC    PCA        noise         KM  normal      1     2   \n",
      "2  WDBC    PCA        noise         KM  normal      1     2   \n",
      "3  WDBC    PCA        noise         KM  normal      1     2   \n",
      "\n",
      "                criteria  Consistency  Accuracy  \n",
      "0                    ARI     0.431333       NaN  \n",
      "1  Fowlkes Mallows Score     0.578000       NaN  \n",
      "2     Mutual Information     0.465000       NaN  \n",
      "3        V Measure Score     0.468000       NaN  \n"
     ]
    }
   ],
   "source": [
    "model2 = imlreliability.dimension_reduction.dimension_reduction(x,estimator=esti,K=len(set(y)),\n",
    "                 label=None,\n",
    "                 perturbation = 'noise',\n",
    "                rank=2,\n",
    "                 sigma=1,\n",
    "                 noise_type='normal',\n",
    "                 n_repeat=3,\n",
    "                    rand_index=1,\n",
    "                    verbose=True)\n",
    "\n",
    "model2.fit()\n",
    "model2.get_consistency_clustering('WDBC','PCA',KMeans(n_clusters=4),'KM')\n",
    "print(model2.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113de1f",
   "metadata": {},
   "source": [
    "###  1.2 Local neighborhood consistency of the reducted dimesions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "characteristic-powell",
   "metadata": {},
   "source": [
    "The ``.get_consistency_knn`` measure local neighborhood consistency of the reduced dimensions, which construct a ``NN-Jaccard-AUC`` pandas dataframe that includes model details and ``NN-Jaccard-AUC`` consistency scores. The resulting dataframe can be downloaded and upload to the dashboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a408239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data method   noise  sigma  rank criteria  Consistency\n",
      "0  WDBC    PCA  normal      1     2  Jaccard     0.565961\n"
     ]
    }
   ],
   "source": [
    "## Nearest neighbor \n",
    "model.get_consistency_knn('WDBC','PCA')\n",
    "# print(model.consistency_knn_mean)\n",
    "print(model.AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2b94a6",
   "metadata": {},
   "source": [
    "### 2. Data spliting\n",
    "\n",
    "We conduct reliability test with data splitting perturbation by simply setting ``perturbation = 'split'``, with all other codes the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7588e7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:  0\n",
      "Iter:  1\n",
      "Iter:  2\n",
      "    data method perturbation clustering   noise  sigma  rank  \\\n",
      "0  WDBC2    PCA        split         KM  normal      1     2   \n",
      "1  WDBC2    PCA        split         KM  normal      1     2   \n",
      "2  WDBC2    PCA        split         KM  normal      1     2   \n",
      "3  WDBC2    PCA        split         KM  normal      1     2   \n",
      "\n",
      "                criteria  Accuracy  Consistency  \n",
      "0                    ARI  0.357667     0.741333  \n",
      "1  Fowlkes Mallows Score  0.620333     0.809333  \n",
      "2     Mutual Information  0.429000     0.760000  \n",
      "3        V Measure Score  0.431333     0.763333  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "esti=PCA()\n",
    "\n",
    "model = imlreliability.dimension_reduction.dimension_reduction(x,estimator=esti,K=len(set(y)),\n",
    "                 label=y,\n",
    "                 perturbation = 'split',\n",
    "                rank=2,\n",
    "                 n_repeat=3,\n",
    "                    rand_index=1,\n",
    "                    verbose=True)\n",
    "\n",
    "model.fit()\n",
    "model.get_consistency_clustering('WDBC2','PCA',KMeans(n_clusters=4),'KM')\n",
    "print(model.results)\n",
    "\n",
    "# model.results.to_csv('dr_clus_new_km_split.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
