{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f3bbe3b",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66faeb56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import imlreliability\n",
    "import pandas as pd\n",
    "import numpy as np#### Load Packages dir(imlreliability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc9c219",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e7ef7",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beeaba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, normalize\n",
    "communities_data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data').to_numpy()\n",
    "communities_data = np.delete(communities_data, np.arange(5), 1)\n",
    "    # remove predictors with missing values\n",
    "communities_data = np.delete(communities_data,\n",
    "                             np.argwhere((communities_data == '?').sum(0) > 0).reshape(-1), 1)\n",
    "communities_data = communities_data.astype(float)\n",
    "x = communities_data[:, :-1]\n",
    "y = communities_data[:, -1]\n",
    "\n",
    "\n",
    "### scale and normalize data \n",
    "x = normalize(scale(x))\n",
    "y = (scale(y))\n",
    "data_reg=(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305ce6ae",
   "metadata": {},
   "source": [
    "### Model specific IML method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccc58e",
   "metadata": {},
   "source": [
    "#### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7527818e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n",
      "Importance Function is  Coef_Ridge\n",
      "          data  model  Accuracy\n",
      "0  communities  Ridge  0.364518\n",
      "1  communities  Ridge  0.435435\n",
      "2  communities  Ridge  0.356309\n",
      "           data      method criteria   K  Consistency  Accuracy\n",
      "0   communities  Coef_Ridge      RBO   1        1.000     0.385\n",
      "1   communities  Coef_Ridge      RBO   2        0.875     0.385\n",
      "2   communities  Coef_Ridge      RBO   3        0.806     0.385\n",
      "3   communities  Coef_Ridge      RBO   4        0.792     0.385\n",
      "4   communities  Coef_Ridge      RBO   5        0.753     0.385\n",
      "5   communities  Coef_Ridge      RBO   6        0.725     0.385\n",
      "6   communities  Coef_Ridge      RBO   7        0.713     0.385\n",
      "7   communities  Coef_Ridge      RBO   8        0.702     0.385\n",
      "8   communities  Coef_Ridge      RBO   9        0.698     0.385\n",
      "9   communities  Coef_Ridge      RBO  10        0.698     0.385\n",
      "10  communities  Coef_Ridge      RBO  11        0.697     0.385\n",
      "11  communities  Coef_Ridge      RBO  12        0.698     0.385\n",
      "12  communities  Coef_Ridge      RBO  13        0.695     0.385\n",
      "13  communities  Coef_Ridge      RBO  14        0.691     0.385\n",
      "14  communities  Coef_Ridge      RBO  15        0.685     0.385\n",
      "15  communities  Coef_Ridge      RBO  16        0.679     0.385\n",
      "16  communities  Coef_Ridge      RBO  17        0.675     0.385\n",
      "17  communities  Coef_Ridge      RBO  18        0.672     0.385\n",
      "18  communities  Coef_Ridge      RBO  19        0.670     0.385\n",
      "19  communities  Coef_Ridge      RBO  20        0.669     0.385\n",
      "20  communities  Coef_Ridge      RBO  21        0.669     0.385\n",
      "21  communities  Coef_Ridge      RBO  22        0.670     0.385\n",
      "22  communities  Coef_Ridge      RBO  23        0.673     0.385\n",
      "23  communities  Coef_Ridge      RBO  24        0.675     0.385\n",
      "24  communities  Coef_Ridge      RBO  25        0.676     0.385\n",
      "25  communities  Coef_Ridge      RBO  26        0.678     0.385\n",
      "26  communities  Coef_Ridge      RBO  27        0.680     0.385\n",
      "27  communities  Coef_Ridge      RBO  28        0.682     0.385\n",
      "28  communities  Coef_Ridge      RBO  29        0.685     0.385\n",
      "29  communities  Coef_Ridge      RBO  30        0.687     0.385\n",
      "30  communities  Coef_Ridge  Jaccard   1        1.000     0.385\n",
      "31  communities  Coef_Ridge  Jaccard   2        0.667     0.385\n",
      "32  communities  Coef_Ridge  Jaccard   3        0.500     0.385\n",
      "33  communities  Coef_Ridge  Jaccard   4        0.667     0.385\n",
      "34  communities  Coef_Ridge  Jaccard   5        0.458     0.385\n",
      "35  communities  Coef_Ridge  Jaccard   6        0.417     0.385\n",
      "36  communities  Coef_Ridge  Jaccard   7        0.511     0.385\n",
      "37  communities  Coef_Ridge  Jaccard   8        0.504     0.385\n",
      "38  communities  Coef_Ridge  Jaccard   9        0.543     0.385\n",
      "39  communities  Coef_Ridge  Jaccard  10        0.576     0.385\n",
      "40  communities  Coef_Ridge  Jaccard  11        0.534     0.385\n",
      "41  communities  Coef_Ridge  Jaccard  12        0.590     0.385\n",
      "42  communities  Coef_Ridge  Jaccard  13        0.517     0.385\n",
      "43  communities  Coef_Ridge  Jaccard  14        0.511     0.385\n",
      "44  communities  Coef_Ridge  Jaccard  15        0.458     0.385\n",
      "45  communities  Coef_Ridge  Jaccard  16        0.440     0.385\n",
      "46  communities  Coef_Ridge  Jaccard  17        0.480     0.385\n",
      "47  communities  Coef_Ridge  Jaccard  18        0.461     0.385\n",
      "48  communities  Coef_Ridge  Jaccard  19        0.470     0.385\n",
      "49  communities  Coef_Ridge  Jaccard  20        0.490     0.385\n",
      "50  communities  Coef_Ridge  Jaccard  21        0.508     0.385\n",
      "51  communities  Coef_Ridge  Jaccard  22        0.548     0.385\n",
      "52  communities  Coef_Ridge  Jaccard  23        0.588     0.385\n",
      "53  communities  Coef_Ridge  Jaccard  24        0.550     0.385\n",
      "54  communities  Coef_Ridge  Jaccard  25        0.542     0.385\n",
      "55  communities  Coef_Ridge  Jaccard  26        0.577     0.385\n",
      "56  communities  Coef_Ridge  Jaccard  27        0.588     0.385\n",
      "57  communities  Coef_Ridge  Jaccard  28        0.578     0.385\n",
      "58  communities  Coef_Ridge  Jaccard  29        0.612     0.385\n",
      "59  communities  Coef_Ridge  Jaccard  30        0.623     0.385\n",
      "          data  model   Entropy    Purity\n",
      "0  communities  Ridge  0.162327  0.852243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "estimator=RidgeCV()\n",
    "importance_func=None\n",
    "import imlreliability\n",
    "\n",
    "model_reg = imlreliability.feature_importance.feature_impoReg(data_reg,estimator=estimator, \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg.fit()\n",
    "model_reg.consistency(data_name='communities', estimator_name='Ridge',impotance_func_name='Coef')\n",
    "print(model_reg.accuracy)\n",
    "print(model_reg.consistency)\n",
    "print(model_reg.prediction_consistency)\n",
    "\n",
    "## model_reg.consistency.to_csv('consis_test_fi_reg.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2cbfa8",
   "metadata": {},
   "source": [
    "#### Tree-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "628a2df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use feature_importances_ as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use feature_importances_ as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use feature_importances_ as feature importance \n",
      "Importance Function is  FI_RF\n",
      "          data model  Accuracy\n",
      "0  communities    RF  0.348597\n",
      "1  communities    RF  0.397374\n",
      "2  communities    RF  0.359101\n",
      "           data method criteria   K  Consistency  Accuracy\n",
      "0   communities  FI_RF      RBO   1        1.000     0.368\n",
      "1   communities  FI_RF      RBO   2        1.000     0.368\n",
      "2   communities  FI_RF      RBO   3        1.000     0.368\n",
      "3   communities  FI_RF      RBO   4        0.938     0.368\n",
      "4   communities  FI_RF      RBO   5        0.890     0.368\n",
      "5   communities  FI_RF      RBO   6        0.881     0.368\n",
      "6   communities  FI_RF      RBO   7        0.857     0.368\n",
      "7   communities  FI_RF      RBO   8        0.843     0.368\n",
      "8   communities  FI_RF      RBO   9        0.830     0.368\n",
      "9   communities  FI_RF      RBO  10        0.822     0.368\n",
      "10  communities  FI_RF      RBO  11        0.818     0.368\n",
      "11  communities  FI_RF      RBO  12        0.812     0.368\n",
      "12  communities  FI_RF      RBO  13        0.803     0.368\n",
      "13  communities  FI_RF      RBO  14        0.791     0.368\n",
      "14  communities  FI_RF      RBO  15        0.785     0.368\n",
      "15  communities  FI_RF      RBO  16        0.781     0.368\n",
      "16  communities  FI_RF      RBO  17        0.775     0.368\n",
      "17  communities  FI_RF      RBO  18        0.772     0.368\n",
      "18  communities  FI_RF      RBO  19        0.773     0.368\n",
      "19  communities  FI_RF      RBO  20        0.772     0.368\n",
      "20  communities  FI_RF      RBO  21        0.772     0.368\n",
      "21  communities  FI_RF      RBO  22        0.772     0.368\n",
      "22  communities  FI_RF      RBO  23        0.773     0.368\n",
      "23  communities  FI_RF      RBO  24        0.772     0.368\n",
      "24  communities  FI_RF      RBO  25        0.772     0.368\n",
      "25  communities  FI_RF      RBO  26        0.773     0.368\n",
      "26  communities  FI_RF      RBO  27        0.774     0.368\n",
      "27  communities  FI_RF      RBO  28        0.775     0.368\n",
      "28  communities  FI_RF      RBO  29        0.776     0.368\n",
      "29  communities  FI_RF      RBO  30        0.776     0.368\n",
      "30  communities  FI_RF  Jaccard   1        1.000     0.368\n",
      "31  communities  FI_RF  Jaccard   2        1.000     0.368\n",
      "32  communities  FI_RF  Jaccard   3        1.000     0.368\n",
      "33  communities  FI_RF  Jaccard   4        0.600     0.368\n",
      "34  communities  FI_RF  Jaccard   5        0.548     0.368\n",
      "35  communities  FI_RF  Jaccard   6        0.750     0.368\n",
      "36  communities  FI_RF  Jaccard   7        0.575     0.368\n",
      "37  communities  FI_RF  Jaccard   8        0.600     0.368\n",
      "38  communities  FI_RF  Jaccard   9        0.568     0.368\n",
      "39  communities  FI_RF  Jaccard  10        0.603     0.368\n",
      "40  communities  FI_RF  Jaccard  11        0.632     0.368\n",
      "41  communities  FI_RF  Jaccard  12        0.607     0.368\n",
      "42  communities  FI_RF  Jaccard  13        0.535     0.368\n",
      "43  communities  FI_RF  Jaccard  14        0.478     0.368\n",
      "44  communities  FI_RF  Jaccard  15        0.539     0.368\n",
      "45  communities  FI_RF  Jaccard  16        0.562     0.368\n",
      "46  communities  FI_RF  Jaccard  17        0.512     0.368\n",
      "47  communities  FI_RF  Jaccard  18        0.565     0.368\n",
      "48  communities  FI_RF  Jaccard  19        0.652     0.368\n",
      "49  communities  FI_RF  Jaccard  20        0.600     0.368\n",
      "50  communities  FI_RF  Jaccard  21        0.648     0.368\n",
      "51  communities  FI_RF  Jaccard  22        0.630     0.368\n",
      "52  communities  FI_RF  Jaccard  23        0.645     0.368\n",
      "53  communities  FI_RF  Jaccard  24        0.602     0.368\n",
      "54  communities  FI_RF  Jaccard  25        0.640     0.368\n",
      "55  communities  FI_RF  Jaccard  26        0.651     0.368\n",
      "56  communities  FI_RF  Jaccard  27        0.662     0.368\n",
      "57  communities  FI_RF  Jaccard  28        0.672     0.368\n",
      "58  communities  FI_RF  Jaccard  29        0.682     0.368\n",
      "59  communities  FI_RF  Jaccard  30        0.644     0.368\n",
      "          data model   Entropy    Purity\n",
      "0  communities    RF  0.162327  0.852243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "estimator=RandomForestRegressor()\n",
    "importance_func=None\n",
    "\n",
    "\n",
    "model_reg_tree=imlreliability.feature_importance.feature_impoReg(data_reg,estimator, \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_tree.fit()\n",
    "model_reg_tree.consistency(data_name='communities', estimator_name='RF',impotance_func_name='FI')\n",
    "print(model_reg_tree.accuracy)\n",
    "print(model_reg_tree.consistency)\n",
    "print(model_reg_tree.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8dcc1e",
   "metadata": {},
   "source": [
    "### Model agnostic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bad43b",
   "metadata": {},
   "source": [
    "#### Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06725fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m importance_func \u001b[38;5;241m=\u001b[39m permutation_importance \u001b[38;5;66;03m## change the importance function to be permutation \u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_reg_tree_per\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoReg(data_reg,estimator, \n\u001b[1;32m      8\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m      9\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     10\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel_reg_tree_per\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model_reg_tree_per\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommunities\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermutation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_reg_tree_per\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/Documents/Documents - Melinda/IML_reliability/imlreliability/feature_importance/_feature_impo.py:219\u001b[0m, in \u001b[0;36mfeature_impoReg.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m(scale(y_test))\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[0;32m--> 219\u001b[0m s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impo_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m this_yhat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted\u001b[38;5;241m.\u001b[39mpredict(x_test)\n\u001b[1;32m    222\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_fun(this_yhat,y_test)\n",
      "File \u001b[0;32m~/Documents/Documents - Melinda/IML_reliability/imlreliability/feature_importance/_feature_impo.py:282\u001b[0m, in \u001b[0;36mfeature_impoReg._impo_score\u001b[0;34m(self, x_train, y_train, x_test)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m#                 fi = [] ## randomly choose 100 observations  \u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m#                 r = np.random.RandomState()\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m#                 idx_I = np.sort(r.choice(len(x_test), size=max(100,len(x_test)), replace=False)) # uniform sampling of subset of observations\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m#                     fi.append([a[1] for a in sorted(mapp[list(mapp.keys())[0]])])\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m#                 s=np.array(fi).mean(0)\u001b[39;00m\n\u001b[1;32m    281\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_permutation_importance\u001b[39m\u001b[38;5;124m'\u001b[39m,impo_pack):\n\u001b[0;32m--> 282\u001b[0m                 s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitted\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mimportances_mean\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;66;03m#### use user-defined importance function\u001b[39;00m\n\u001b[1;32m    284\u001b[0m         \n\u001b[1;32m    285\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m                 s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitted,x_train, y_train)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/inspection/_permutation_importance.py:259\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    255\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m _MultimetricScorer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscorers_dict)\n\u001b[1;32m    257\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[0;32m--> 259\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calculate_permutation_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    276\u001b[0m         name: _create_importances_bunch(\n\u001b[1;32m    277\u001b[0m             baseline_score[name],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_score\n\u001b[1;32m    282\u001b[0m     }\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/inspection/_permutation_importance.py:64\u001b[0m, in \u001b[0;36m_calculate_permutation_scores\u001b[0;34m(estimator, X, y, sample_weight, col_idx, random_state, n_repeats, scorer, max_samples)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m         X_permuted[:, col_idx] \u001b[38;5;241m=\u001b[39m X_permuted[shuffling_idx, col_idx]\n\u001b[0;32m---> 64\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_weights_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_permuted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scores[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     67\u001b[0m     scores \u001b[38;5;241m=\u001b[39m _aggregate_score_dicts(scores)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/inspection/_permutation_importance.py:19\u001b[0m, in \u001b[0;36m_weights_scorer\u001b[0;34m(scorer, estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(estimator, X, y, sample_weight)\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:429\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_passthrough_scorer\u001b[39m(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;124;03m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:720\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;124;03m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m--> 720\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:1004\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;66;03m# Parallel loop\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m lock \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mLock()\n\u001b[0;32m-> 1004\u001b[0m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequire\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msharedmem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_accumulate_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m y_hat \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_)\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_hat\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:664\u001b[0m, in \u001b[0;36m_accumulate_prediction\u001b[0;34m(predict, X, out, lock)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_accumulate_prediction\u001b[39m(predict, X, out, lock):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;124;03m    This is a utility function for joblib's Parallel.\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m    It can't go locally in ForestClassifier or ForestRegressor, because joblib\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;124;03m    complains that it cannot pickle it when placed there.\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[1;32m    666\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:506\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    504\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    505\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X, check_input)\n\u001b[0;32m--> 506\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# Classification\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "estimator=RandomForestRegressor()\n",
    "importance_func = permutation_importance ## change the importance function to be permutation \n",
    "\n",
    "\n",
    "model_reg_tree_per=imlreliability.feature_importance.feature_impoReg(data_reg,estimator, \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_tree_per.fit()\n",
    "model_reg_tree_per.consistency(data_name='communities', estimator_name='RF',impotance_func_name='Permutation')\n",
    "print(model_reg_tree_per.accuracy)\n",
    "print(model_reg_tree_per.consistency)\n",
    "print(model_reg_tree_per.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce05eb",
   "metadata": {},
   "source": [
    "#### Shapley Value \n",
    "\n",
    "###### error: cant import shap package, reinstall shap downgrade numpy to 1.21.6, while tensorflow needs 1.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c23f45",
   "metadata": {},
   "source": [
    "we provide built-in importance functions from package shap and perumutation function from sklearn.inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e590710",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "\n",
    "importance_func(self.fitted,x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a523664c",
   "metadata": {},
   "source": [
    "### MLP+DeepExplain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c5bfc",
   "metadata": {},
   "source": [
    "We have built-in functions to run functions from deepexplain and  deeplift packages. As well permutation and shapley values. User can either input a function or a string from [\n",
    "                        'zero',\n",
    "                        'saliency',\n",
    "                        'grad*input',\n",
    "                        'intgrad',\n",
    "                        'elrp',\n",
    "                        'deeplift',\n",
    "                        'occlusion',\n",
    "                        'shapley_sampling'] to run deepExplain. \n",
    "Or input strings from ['NonlinearMxtsMode.RevealCancel','NonlinearMxtsMode.GuidedBackprop'...] to run corresponding functions in deeplift. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb504161",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "    importance_func(model,x_train, y_train). Where model is .h5 file of MLP model. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d448d13",
   "metadata": {},
   "source": [
    "defined estimator needs to be form of :\n",
    "    def _base_model_classification():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8a180",
   "metadata": {},
   "source": [
    "#### Permutation+MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b54329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Metal device set to: Apple M1\n",
      "Iter:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 22:40:31.027917: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-21 22:40:31.027938: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "2023-02-21 22:40:31.176926: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 1s 10ms/step - loss: 0.7419\n",
      "['eli5', 'sklearn', 'permutation_importance']\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7660\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4844\n",
      "13/19 [===================>..........] - ETA: 0s - loss: 0.4930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4902\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4922\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4922\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4855\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4872\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4840\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4864\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4876\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4860\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4878\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4862\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4863\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4820\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4828\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4834\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4832\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4928\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4839\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4884\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4837\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4832\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4876\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4869\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4882\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4889\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4889\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4931\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4976\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4820\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4836\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4859\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4828\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4836\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4884\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4860\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4835\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4867\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4816\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4834\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4836\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4881\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4867\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4880\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4867\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4823\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4837\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4936\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4879\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4824\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4876\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4878\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4832\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4880\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4907\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4904\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4970\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4858\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4862\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4835\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4855\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4880\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4860\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4827\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4911\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4853\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4860\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4853\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4889\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4894\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4888\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4885\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4948\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4858\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4988\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4858\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4836\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4808\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4817\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4812\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4836\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4833\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4855\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4896\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4855\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4880\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4840\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4830\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4906\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4867\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4911\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4855\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4874\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4863\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4839\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4928\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4881\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4820\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4870\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4901\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4832\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4870\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4892\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4908\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4950\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4860\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4859\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4853\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4885\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4833\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4858\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4863\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4882\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4835\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4824\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4829\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4836\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4840\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4929\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4833\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4862\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4862\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4853\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4880\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4864\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4872\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4905\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4908\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4892\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4883\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4949\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5010\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4828\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4808\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4829\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4837\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4834\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4833\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4837\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4891\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4863\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4862\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4858\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4824\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4830\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4893\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4886\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4860\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4882\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4853\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4937\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4899\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4820\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4840\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4896\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4883\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4880\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4901\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4854\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4931\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4957\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4863\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4867\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4870\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4840\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4855\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4881\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4868\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4831\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4839\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4836\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4833\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4834\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4897\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4868\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4858\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4839\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4863\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4858\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4892\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4903\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4910\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4947\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4864\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5004\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4859\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4834\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4806\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4825\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4840\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4826\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4827\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4836\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4837\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4893\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4873\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4825\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4884\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4864\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4862\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4840\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4926\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4873\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4837\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4833\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4873\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4839\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4874\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4878\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4889\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4929\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4976\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4865\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4861\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4852\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4907\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4880\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4856\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4831\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4833\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4835\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4921\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4840\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4853\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4855\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4839\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4890\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4867\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4855\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4877\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4867\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4892\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4870\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4872\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4933\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4860\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5006\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4832\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4810\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4824\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4853\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4839\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4828\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4831\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4834\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4908\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4870\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4841\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4840\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4857\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4835\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4859\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4837\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4903\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4870\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4847\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4848\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4849\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4832\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4836\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4844\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4843\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4964\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4885\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4845\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4851\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4829\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4864\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4882\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4846\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4873\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4850\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.4643\n",
      "Iter:  1\n",
      "18/44 [===========>..................] - ETA: 0s - loss: 0.4432"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 9ms/step - loss: 0.3998\n",
      "['eli5', 'sklearn', 'permutation_importance']\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.7563\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5381\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5403\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5320\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5336\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5314\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5335\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5279\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5307\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5326\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5321\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5285\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5260\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5261\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5288\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5278\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5278\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5359\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5285\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5278\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5328\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5317\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5316\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5346\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5316\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5329\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5338\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5376\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5283\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5328\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5441\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5308\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5262\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5281\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5284\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5324\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5308\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5313\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5345\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5325\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5273\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5282\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5329\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5314\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5292\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5327\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5322\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5283\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5289\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5307\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5302\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5307\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5333\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5325\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5322\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5275\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5339\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5281\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5314\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5324\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5354\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5335\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5389\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5444\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5307\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5312\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5340\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5312\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5335\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5290\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5293\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5325\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5308\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5313\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5255\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5276\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5275\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5275\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5315\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5280\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5288\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5293\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5263\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5302\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5290\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5339\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5317\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5325\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5321\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5321\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5354\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5359\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5335\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5390\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5313\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5419\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5325\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5285\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5266\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5290\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5316\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5315\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5325\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5286\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5330\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5292\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5279\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5334\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5262\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5293\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5280\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5332\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5327\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5328\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5270\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5323\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5274\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5288\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5322\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5332\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5288\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5327\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5359\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5421\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5314\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5328\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5330\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5290\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5318\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5312\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5324\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5302\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5355\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5279\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5285\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5289\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5383\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5294\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5312\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5302\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5291\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5331\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5319\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5338\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5316\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5356\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5369\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5286\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5323\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5454\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5313\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5269\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5286\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5314\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5352\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5291\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5319\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5333\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5308\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5272\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5290\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5279\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5351\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5322\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5336\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5283\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5320\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5294\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5289\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5282\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5308\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5307\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5358\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5318\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5323\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5293\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5327\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5281\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5334\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5308\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5343\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5334\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5335\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5376\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5411\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5324\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5284\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5341\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5289\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5288\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5294\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5314\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5290\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5290\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5278\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5294\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5320\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5278\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5276\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5284\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5274\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5315\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5302\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5278\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5334\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5308\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5322\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5348\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5323\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5320\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5351\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5339\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5391\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5280\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5307\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5322\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5438\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5314\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5278\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5280\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5315\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5319\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5342\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5328\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5314\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5258\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5313\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5291\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5320\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5283\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5313\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5302\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5286\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5315\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5294\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5274\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5289\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5316\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5374\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5328\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5271\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5326\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5284\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5331\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5318\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5318\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5323\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5342\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5316\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5396\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5387\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5332\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5324\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5294\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5331\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5292\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5323\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5322\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5310\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5263\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5282\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5290\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5280\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5271\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5296\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5280\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5289\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5288\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5283\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5298\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5302\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5291\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5355\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5304\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5314\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5332\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5316\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5351\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5353\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5312\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5376\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5291\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5302\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5322\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5420\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5321\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5258\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5320\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5299\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5309\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5326\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5316\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5308\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5303\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5322\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5250\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5320\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5286\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5294\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5344\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5300\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5318\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5334\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5301\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5307\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5290\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5302\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5306\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5307\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5295\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5313\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5305\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5325\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5327\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5323\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5326\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5285\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5328\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5287\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5323\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5311\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5347\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5297\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.4435\n",
      "Iter:  2\n",
      "18/44 [===========>..................] - ETA: 0s - loss: 0.4011"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 10ms/step - loss: 0.3815\n",
      "['eli5', 'sklearn', 'permutation_importance']\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.7704\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4753\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4791\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4690\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4715\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4667\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4708\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4654\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4672\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4659\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4663\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4656\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4667\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4662\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4652\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4745\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4687\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4702\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4664\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4706\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4705\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4731\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4672\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4717\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4723\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4703\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4747\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4691\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4871\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4672\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4658\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4669\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4729\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4663\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4717\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4691\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4669\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4745\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4722\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4690\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4704\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4651\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4709\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4683\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4664\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4670\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4665\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4667\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4764\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4695\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4689\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4668\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4718\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4704\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4683\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4705\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4758\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4791\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4672\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4700\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4693\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4710\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4660\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4698\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4701\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4695\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4650\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4658\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4649\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4662\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4653\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4767\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4689\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4659\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4656\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4636\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4661\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4720\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4700\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4739\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4739\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4729\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4700\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4759\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4842\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4650\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4660\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4732\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4667\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4668\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4692\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4668\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4693\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4666\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4756\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4713\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4707\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4706\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4694\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4691\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4667\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4758\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4716\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4689\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4696\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4705\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4716\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4695\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4701\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4779\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4785\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4689\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4694\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4714\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4668\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4693\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4693\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4665\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4649\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4734\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4689\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4666\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4659\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4672\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4718\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4717\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4702\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4731\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4722\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4707\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4775\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4696\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4808\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4652\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4663\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4723\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4699\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4670\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4691\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4714\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4694\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4666\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4743\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4692\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4754\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4705\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4683\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4669\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4702\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4655\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4663\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4666\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4670\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4742\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4708\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4694\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4690\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4707\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4672\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4728\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4700\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4762\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4788\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4683\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4670\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4687\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4717\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4660\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4699\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4689\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4670\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4662\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4670\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4664\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4661\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4648\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4736\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4669\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4666\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4666\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4695\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4741\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4689\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4723\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4713\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4802\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4695\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4827\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4694\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4663\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4695\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4721\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4690\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4662\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4665\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4687\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4707\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4667\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4687\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4765\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4708\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4710\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4687\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4660\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4669\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4659\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4668\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4790\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4712\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4698\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4691\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4700\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4684\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4751\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4797\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4668\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4718\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4683\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4673\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4665\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4656\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4658\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4675\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4660\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4645\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4754\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4660\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4662\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4671\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4655\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4669\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4658\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4667\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4703\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4696\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4699\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4736\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4737\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4691\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4748\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4676\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4871\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4683\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4656\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4693\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4685\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4723\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4664\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4669\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4709\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4692\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4688\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4656\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4681\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4680\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4683\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4749\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4721\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4712\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4669\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4658\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4674\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4687\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4668\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4678\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4735\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4712\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4682\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4663\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4679\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4692\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4677\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4713\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4686\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4697\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4721\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.3407\n",
      "Importance Function is  Permutation_MLP\n",
      "          data model  Accuracy\n",
      "0  communities   MLP  0.464279\n",
      "1  communities   MLP  0.443495\n",
      "2  communities   MLP  0.340747\n",
      "           data           method criteria   K  Consistency  Accuracy\n",
      "0   communities  Permutation_MLP      RBO   1        1.000     0.416\n",
      "1   communities  Permutation_MLP      RBO   2        1.000     0.416\n",
      "2   communities  Permutation_MLP      RBO   3        1.000     0.416\n",
      "3   communities  Permutation_MLP      RBO   4        0.938     0.416\n",
      "4   communities  Permutation_MLP      RBO   5        0.930     0.416\n",
      "5   communities  Permutation_MLP      RBO   6        0.914     0.416\n",
      "6   communities  Permutation_MLP      RBO   7        0.896     0.416\n",
      "7   communities  Permutation_MLP      RBO   8        0.870     0.416\n",
      "8   communities  Permutation_MLP      RBO   9        0.847     0.416\n",
      "9   communities  Permutation_MLP      RBO  10        0.832     0.416\n",
      "10  communities  Permutation_MLP      RBO  11        0.823     0.416\n",
      "11  communities  Permutation_MLP      RBO  12        0.817     0.416\n",
      "12  communities  Permutation_MLP      RBO  13        0.810     0.416\n",
      "13  communities  Permutation_MLP      RBO  14        0.803     0.416\n",
      "14  communities  Permutation_MLP      RBO  15        0.799     0.416\n",
      "15  communities  Permutation_MLP      RBO  16        0.796     0.416\n",
      "16  communities  Permutation_MLP      RBO  17        0.795     0.416\n",
      "17  communities  Permutation_MLP      RBO  18        0.793     0.416\n",
      "18  communities  Permutation_MLP      RBO  19        0.791     0.416\n",
      "19  communities  Permutation_MLP      RBO  20        0.788     0.416\n",
      "20  communities  Permutation_MLP      RBO  21        0.787     0.416\n",
      "21  communities  Permutation_MLP      RBO  22        0.786     0.416\n",
      "22  communities  Permutation_MLP      RBO  23        0.784     0.416\n",
      "23  communities  Permutation_MLP      RBO  24        0.782     0.416\n",
      "24  communities  Permutation_MLP      RBO  25        0.780     0.416\n",
      "25  communities  Permutation_MLP      RBO  26        0.778     0.416\n",
      "26  communities  Permutation_MLP      RBO  27        0.776     0.416\n",
      "27  communities  Permutation_MLP      RBO  28        0.773     0.416\n",
      "28  communities  Permutation_MLP      RBO  29        0.770     0.416\n",
      "29  communities  Permutation_MLP      RBO  30        0.766     0.416\n",
      "30  communities  Permutation_MLP  Jaccard   1        1.000     0.416\n",
      "31  communities  Permutation_MLP  Jaccard   2        1.000     0.416\n",
      "32  communities  Permutation_MLP  Jaccard   3        1.000     0.416\n",
      "33  communities  Permutation_MLP  Jaccard   4        0.600     0.416\n",
      "34  communities  Permutation_MLP  Jaccard   5        0.833     0.416\n",
      "35  communities  Permutation_MLP  Jaccard   6        0.714     0.416\n",
      "36  communities  Permutation_MLP  Jaccard   7        0.653     0.416\n",
      "37  communities  Permutation_MLP  Jaccard   8        0.527     0.416\n",
      "38  communities  Permutation_MLP  Jaccard   9        0.510     0.416\n",
      "39  communities  Permutation_MLP  Jaccard  10        0.548     0.416\n",
      "40  communities  Permutation_MLP  Jaccard  11        0.579     0.416\n",
      "41  communities  Permutation_MLP  Jaccard  12        0.607     0.416\n",
      "42  communities  Permutation_MLP  Jaccard  13        0.577     0.416\n",
      "43  communities  Permutation_MLP  Jaccard  14        0.560     0.416\n",
      "44  communities  Permutation_MLP  Jaccard  15        0.583     0.416\n",
      "45  communities  Permutation_MLP  Jaccard  16        0.604     0.416\n",
      "46  communities  Permutation_MLP  Jaccard  17        0.660     0.416\n",
      "47  communities  Permutation_MLP  Jaccard  18        0.601     0.416\n",
      "48  communities  Permutation_MLP  Jaccard  19        0.618     0.416\n",
      "49  communities  Permutation_MLP  Jaccard  20        0.569     0.416\n",
      "50  communities  Permutation_MLP  Jaccard  21        0.618     0.416\n",
      "51  communities  Permutation_MLP  Jaccard  22        0.632     0.416\n",
      "52  communities  Permutation_MLP  Jaccard  23        0.588     0.416\n",
      "53  communities  Permutation_MLP  Jaccard  24        0.574     0.416\n",
      "54  communities  Permutation_MLP  Jaccard  25        0.591     0.416\n",
      "55  communities  Permutation_MLP  Jaccard  26        0.577     0.416\n",
      "56  communities  Permutation_MLP  Jaccard  27        0.566     0.416\n",
      "57  communities  Permutation_MLP  Jaccard  28        0.535     0.416\n",
      "58  communities  Permutation_MLP  Jaccard  29        0.507     0.416\n",
      "59  communities  Permutation_MLP  Jaccard  30        0.482     0.416\n",
      "          data model   Entropy    Purity\n",
      "0  communities   MLP  0.162327  0.852243\n"
     ]
    }
   ],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "importance_func =PermutationImportance\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_reg_mlp_dl=imlreliability.feature_importance.feature_impoReg_MLP(data_reg,\n",
    "                                                                           \n",
    "                 importance_func=PermutationImportance,\n",
    "                 n_repeat=1,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_mlp_dl.fit()\n",
    "model_reg_mlp_dl.consistency(data_name='communities', estimator_name='MLP',impotance_func_name='Permutation')\n",
    "print(model_reg_mlp_dl.accuracy)\n",
    "print(model_reg_mlp_dl.consistency)\n",
    "print(model_reg_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a78df",
   "metadata": {},
   "source": [
    "#### Deeplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981fe9e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Iter:  0\n",
      "12/44 [=======>......................] - ETA: 0s - loss: 1.0511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7807\n",
      "DeepLift\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"KeysViewHDF5\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_reg_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoReg_MLP(data_reg,\n\u001b[1;32m      8\u001b[0m                                                                            \n\u001b[1;32m      9\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m     10\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     11\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel_reg_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model_reg_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommunities\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_reg_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/Documents/Documents - Melinda/IML_reliability/imlreliability/feature_importance/_feature_impo.py:672\u001b[0m, in \u001b[0;36mfeature_impoReg_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_file\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp_reg_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 672\u001b[0m         s\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impo_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m##### different in MLP!\u001b[39;00m\n\u001b[1;32m    676\u001b[0m         acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Documents - Melinda/IML_reliability/imlreliability/feature_importance/_feature_impo.py:622\u001b[0m, in \u001b[0;36mfeature_impoReg_MLP._impo_score\u001b[0;34m(self, x_train, y_train, x_test, y_test)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeeplift\u001b[39m\u001b[38;5;124m'\u001b[39m,impo_pack):\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 622\u001b[0m     dl_model \u001b[38;5;241m=\u001b[39m \u001b[43mkc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_model_from_saved_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mh5_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mnonlinear_mxts_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance_func\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m     dl_func \u001b[38;5;241m=\u001b[39m dl_model\u001b[38;5;241m.\u001b[39mget_target_contribs_func(find_scores_layer_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m    627\u001b[0m                                                 target_layer_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_layer)\n\u001b[1;32m    628\u001b[0m     method_name, score_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_func, dl_func\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deeplift/conversion/kerasapi_conversion.py:387\u001b[0m, in \u001b[0;36mconvert_model_from_saved_files\u001b[0;34m(h5_file, json_file, yaml_file, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_config \u001b[38;5;129;01min\u001b[39;00m layer_configs:\n\u001b[1;32m    385\u001b[0m     layer_name \u001b[38;5;241m=\u001b[39m layer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m layer_name \u001b[38;5;129;01min\u001b[39;00m model_weights,\\\n\u001b[0;32m--> 387\u001b[0m         (\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLayer \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mlayer_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m is in the layer names but not in the \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    388\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m weights file which has layer names \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmodel_weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (layer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    391\u001b[0m         nested_model_weights \u001b[38;5;241m=\u001b[39m\\\n\u001b[1;32m    392\u001b[0m             OrderedDict(\u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    393\u001b[0m              model_weights[layer_name]\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_names\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    394\u001b[0m              [model_weights[layer_name][x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m    395\u001b[0m               model_weights[layer_name]\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]]))\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"KeysViewHDF5\") to str"
     ]
    }
   ],
   "source": [
    "from deeplift.layers import NonlinearMxtsMode\n",
    "import deeplift\n",
    "importance_func = 'NonlinearMxtsMode.RevealCancel'\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_reg_mlp_dl=imlreliability.feature_importance.feature_impoReg_MLP(data_reg,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_mlp_dl.fit()\n",
    "model_reg_mlp_dl.consistency(data_name='communities', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_reg_mlp_dl.accuracy)\n",
    "print(model_reg_mlp_dl.consistency)\n",
    "print(model_reg_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba1da12",
   "metadata": {},
   "source": [
    "#### deepexplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4b7e9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deepexplain package reuqires numpy =1.22.4, tf will have error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99195e9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepexplain'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepexplain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepExplain\n\u001b[1;32m      2\u001b[0m importance_func \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melrp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'deepexplain'"
     ]
    }
   ],
   "source": [
    "from deepexplain.tensorflow import DeepExplain\n",
    "importance_func ='elrp'\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_reg_mlp_dl=imlreliability.feature_importance.feature_impoReg_MLP(data_reg,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_reg_mlp_dl.fit()\n",
    "model_reg_mlp_dl.consistency(data_name='communities', estimator_name='MLP',impotance_func_name='elrp')\n",
    "print(model_reg_mlp_dl.accuracy)\n",
    "print(model_reg_mlp_dl.consistency)\n",
    "print(model_reg_mlp_dl.prediction_consistency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fed87f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
