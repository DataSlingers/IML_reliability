{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53aeef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np#### Load Packages dir(imlreliability)\n",
    "\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "communities_data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data').to_numpy()\n",
    "communities_data = np.delete(communities_data, np.arange(5), 1)\n",
    "    # remove predictors with missing values\n",
    "communities_data = np.delete(communities_data,\n",
    "                             np.argwhere((communities_data == '?').sum(0) > 0).reshape(-1), 1)\n",
    "communities_data = communities_data.astype(float)\n",
    "x = communities_data[:, :-1]\n",
    "y = communities_data[:, -1]\n",
    "\n",
    "\n",
    "### scale and normalize data \n",
    "x = normalize(scale(x))\n",
    "y = (scale(y))\n",
    "data_reg=(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54668920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "M=len(x[0])\n",
    "noise='split'\n",
    "i=0\n",
    "var=1\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.3,random_state=i*1234+7)\n",
    "x_train=preprocessing.scale(x_train)\n",
    "x_test =preprocessing.scale(x_test)\n",
    "y_train =preprocessing.scale(y_train)\n",
    "y_test =preprocessing.scale(y_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130952b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 15:19:47.586474: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-05-16 15:19:47.586496: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 15:19:47.831134: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-05-16 15:19:47.947925: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.5257\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3431\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.3205\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2996\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2798\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2613\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.2389\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2371\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2161\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1986\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train,y_train, epochs=10, batch_size=50)\n",
    "model_json = model.to_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a6c8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"checkdl.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#                     # serialize weights to HDF5\n",
    "model.save(\"checkdl.h5\")\n",
    "\n",
    "saved_model_file=\"checkdl.h5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ffac607",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'get_default_session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepexplain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepExplain\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method_name,func_name \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m      3\u001b[0m                               (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntegratedGradients\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintgrad\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      4\u001b[0m                           ]:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing scores for:\u001b[39m\u001b[38;5;124m\"\u001b[39m,method_name)\n",
      "File \u001b[0;32m~/src/deepexplain/deepexplain/tensorflow/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmethods\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepExplain\n",
      "File \u001b[0;32m~/src/deepexplain/deepexplain/tensorflow/methods.py:557\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_grad(op, grad)\n\u001b[0;32m--> 557\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDeepExplain\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mget_default_session()):\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/src/deepexplain/deepexplain/tensorflow/methods.py:559\u001b[0m, in \u001b[0;36mDeepExplain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDeepExplain\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_session\u001b[49m()):\n\u001b[1;32m    560\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'get_default_session'"
     ]
    }
   ],
   "source": [
    "from deepexplain.tensorflow import DeepExplain\n",
    "for method_name,func_name in [\n",
    "                              ('IntegratedGradients','intgrad'),\n",
    "                          ]:\n",
    "    print(\"Computing scores for:\",method_name)\n",
    "    scores,ranks={},{}\n",
    "    scores[method_name],ranks[method_name]=[],[]\n",
    "\n",
    "    with DeepExplain(session=K.get_session()) as de:  # <-- init DeepExplain context\n",
    "            # Need to reconstruct the graph in DeepExplain context, using the same weights.\n",
    "            # With Keras this is very easy:\n",
    "            # 1. Get the input tensor to the original model\n",
    "            input_tensor = model.layers[0].input\n",
    "\n",
    "            # 2. We now target the output of the last dense layer (pre-softmax)\n",
    "            # To do so, create a new model sharing the same layers untill the last dense (index -2)\n",
    "            fModel = Model(inputs=input_tensor, outputs = model.layers[-2].output)\n",
    "            target_tensor = fModel(input_tensor)\n",
    "\n",
    "            xs = x_test\n",
    "            ys = np.reshape(y_test, (len(y_test),  1))  \n",
    "            attributions = de.explain(func_name, target_tensor, input_tensor, xs, ys=ys)\n",
    "\n",
    "\n",
    "\n",
    "    ss=attributions.mean(0)\n",
    "    s,r=get_sr_reg(ss,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8542c67",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"KeysViewHDF5\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplift\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NonlinearMxtsMode\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplift\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kerasapi_conversion \u001b[38;5;28;01mas\u001b[39;00m kc\n\u001b[0;32m----> 8\u001b[0m revealcancel_model \u001b[38;5;241m=\u001b[39m \u001b[43mkc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_model_from_saved_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mh5_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaved_model_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnonlinear_mxts_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNonlinearMxtsMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRevealCancel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m revealcancel_func \u001b[38;5;241m=\u001b[39m revealcancel_model\u001b[38;5;241m.\u001b[39mget_target_contribs_func(find_scores_layer_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, target_layer_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/deeplift/conversion/kerasapi_conversion.py:387\u001b[0m, in \u001b[0;36mconvert_model_from_saved_files\u001b[0;34m(h5_file, json_file, yaml_file, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_config \u001b[38;5;129;01min\u001b[39;00m layer_configs:\n\u001b[1;32m    385\u001b[0m     layer_name \u001b[38;5;241m=\u001b[39m layer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m layer_name \u001b[38;5;129;01min\u001b[39;00m model_weights,\\\n\u001b[0;32m--> 387\u001b[0m         (\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLayer \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mlayer_name\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m is in the layer names but not in the \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    388\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m weights file which has layer names \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mmodel_weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (layer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSequential\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m    391\u001b[0m         nested_model_weights \u001b[38;5;241m=\u001b[39m\\\n\u001b[1;32m    392\u001b[0m             OrderedDict(\u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    393\u001b[0m              model_weights[layer_name]\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_names\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    394\u001b[0m              [model_weights[layer_name][x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m\n\u001b[1;32m    395\u001b[0m               model_weights[layer_name]\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]]))\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"KeysViewHDF5\") to str"
     ]
    }
   ],
   "source": [
    "import deeplift\n",
    "from deeplift.layers import NonlinearMxtsMode\n",
    "from deeplift.conversion import kerasapi_conversion as kc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "revealcancel_model = kc.convert_model_from_saved_files(\n",
    "                        h5_file=saved_model_file,\n",
    "                        nonlinear_mxts_mode=NonlinearMxtsMode.RevealCancel)\n",
    "\n",
    "revealcancel_func = revealcancel_model.get_target_contribs_func(find_scores_layer_idx=0, target_layer_idx=-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bab5d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkdl.h5'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a54aa623",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'revealcancel_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method_name, score_func \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m----> 2\u001b[0m                            (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrevealcancel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mrevealcancel_func\u001b[49m),\n\u001b[1;32m      3\u001b[0m                             ]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method_name \u001b[38;5;129;01min\u001b[39;00m need_to_run:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing scores for:\u001b[39m\u001b[38;5;124m\"\u001b[39m,method_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'revealcancel_func' is not defined"
     ]
    }
   ],
   "source": [
    "for method_name, score_func in [\n",
    "                           ('revealcancel', revealcancel_func),\n",
    "                            ]:\n",
    "    if method_name in need_to_run:\n",
    "        print(\"Computing scores for:\",method_name)\n",
    "        scores,ranks={},{}\n",
    "        scores[method_name],ranks[method_name]=[],[]\n",
    "\n",
    "        method_to_task_to_scores = {}\n",
    "        scor = np.array(score_func(\n",
    "                        task_idx=0,\n",
    "                        input_data_list=[x_test],\n",
    "                        input_references_list=[np.zeros_like(x_test)],\n",
    "                        batch_size=100,\n",
    "                        progress_update=None))\n",
    "\n",
    "        s,r=get_sr_reg(scor.mean(0),M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ced54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182e562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for method_name, score_func in [\n",
    "                           ('guided_backprop_masked', guided_backprop_func_masked)\n",
    "                            ]:\n",
    "    if method_name in need_to_run:\n",
    "        print(\"Computing scores for:\",method_name)\n",
    "        scores,ranks={},{}\n",
    "        scores[method_name],ranks[method_name]=[],[]\n",
    "\n",
    "        method_to_task_to_scores = {}\n",
    "        scor = np.array(score_func(\n",
    "                        task_idx=0,\n",
    "                        input_data_list=[x_test],\n",
    "                        input_references_list=[np.zeros_like(x_test)],\n",
    "                        batch_size=100,\n",
    "                        progress_update=None))\n",
    "\n",
    "        s,r=get_sr_reg(scor.mean(0),M)\n",
    "\n",
    "guided_backprop_model = kc.convert_model_from_saved_files(\n",
    "                            h5_file=saved_model_file,\n",
    "                            nonlinear_mxts_mode=NonlinearMxtsMode.GuidedBackprop)\n",
    "guided_backprop_func = guided_backprop_model.get_target_multipliers_func(find_scores_layer_idx=0, target_layer_idx=-2)\n",
    "guided_backprop_func_masked = lambda input_data_list, **kwargs: ((input_data_list[0]>0.0)*\n",
    "                           guided_backprop_func(input_data_list=input_data_list, **kwargs))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
