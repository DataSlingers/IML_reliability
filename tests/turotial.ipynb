{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec46eb37",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66faeb56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import imlreliability\n",
    "import pandas as pd\n",
    "import numpy as np#### Load Packages dir(imlreliability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fed0a69",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aacb6a",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d01b4b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, normalize\n",
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Class']\n",
    "data =  pd.read_csv(csv_url, names = col_names)\n",
    "y =(data['Class'])\n",
    "x = data[['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']]\n",
    "\n",
    "### scale and normalize data \n",
    "x = normalize(scale(x))\n",
    "data_class=(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb42f2df",
   "metadata": {},
   "source": [
    "### Model specific IML method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899873c6",
   "metadata": {},
   "source": [
    "#### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0036f47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n",
      "3\n",
      "Iter:  3\n",
      "use coefs as feature importance \n",
      "4\n",
      "Iter:  4\n",
      "use coefs as feature importance \n",
      "5\n",
      "Iter:  5\n",
      "use coefs as feature importance \n",
      "6\n",
      "Iter:  6\n",
      "use coefs as feature importance \n",
      "7\n",
      "Iter:  7\n",
      "use coefs as feature importance \n",
      "8\n",
      "Iter:  8\n",
      "use coefs as feature importance \n",
      "9\n",
      "Iter:  9\n",
      "use coefs as feature importance \n",
      "Importance Function is  Coef_LogisticRidge\n",
      "   data          model  Accuracy\n",
      "0  Iris  LogisticRidge  0.822222\n",
      "1  Iris  LogisticRidge  0.777778\n",
      "2  Iris  LogisticRidge  0.933333\n",
      "3  Iris  LogisticRidge  0.844444\n",
      "4  Iris  LogisticRidge  0.888889\n",
      "5  Iris  LogisticRidge  0.866667\n",
      "6  Iris  LogisticRidge  0.866667\n",
      "7  Iris  LogisticRidge  0.911111\n",
      "8  Iris  LogisticRidge  0.777778\n",
      "9  Iris  LogisticRidge  0.755556\n",
      "   data              method criteria  K  Consistency  Accuracy\n",
      "0  Iris  Coef_LogisticRidge      RBO  1        0.778     0.844\n",
      "1  Iris  Coef_LogisticRidge      RBO  2        0.889     0.844\n",
      "2  Iris  Coef_LogisticRidge      RBO  3        0.926     0.844\n",
      "3  Iris  Coef_LogisticRidge      RBO  4        0.944     0.844\n",
      "4  Iris  Coef_LogisticRidge  Jaccard  1        0.778     0.844\n",
      "5  Iris  Coef_LogisticRidge  Jaccard  2        1.000     0.844\n",
      "6  Iris  Coef_LogisticRidge  Jaccard  3        1.000     0.844\n",
      "7  Iris  Coef_LogisticRidge  Jaccard  4        1.000     0.844\n",
      "   data          model   Entropy    Purity\n",
      "0  Iris  LogisticRidge  0.073236  0.894342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "estimator=LogisticRegressionCV()\n",
    "importance_func=None\n",
    "\n",
    "model_class = imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=10,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class.fit()\n",
    "model_class.consistency(data_name='Iris', estimator_name='LogisticRidge',impotance_func_name='Coef')\n",
    "print(model_class.accuracy)\n",
    "print(model_class.consistency)\n",
    "print(model_class.prediction_consistency)\n",
    "\n",
    "## model_class.consistency.to_csv('consis_test_fi_class.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e7a79be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRidge</td>\n",
       "      <td>0.073236</td>\n",
       "      <td>0.894342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data          model   Entropy    Purity\n",
       "0  Iris  LogisticRidge  0.073236  0.894342"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.prediction_consistency.groupby(['data','model']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a6b75",
   "metadata": {},
   "source": [
    "#### Tree-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be90a0a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n",
      "Importance Function is  FI_RF\n",
      "   data model  Accuracy\n",
      "0  Iris    RF  0.822222\n",
      "1  Iris    RF  0.777778\n",
      "2  Iris    RF  0.933333\n",
      "   data method criteria  K  Consistency  Accuracy\n",
      "0  Iris  FI_RF      RBO  1        0.500     0.844\n",
      "1  Iris  FI_RF      RBO  2        0.750     0.844\n",
      "2  Iris  FI_RF      RBO  3        0.833     0.844\n",
      "3  Iris  FI_RF      RBO  4        0.875     0.844\n",
      "4  Iris  FI_RF  Jaccard  1        0.500     0.844\n",
      "5  Iris  FI_RF  Jaccard  2        1.000     0.844\n",
      "6  Iris  FI_RF  Jaccard  3        1.000     0.844\n",
      "7  Iris  FI_RF  Jaccard  4        1.000     0.844\n",
      "     Entropy  data model  Purity\n",
      "0       -0.0  Iris    RF     1.0\n",
      "1       -0.0  Iris    RF     1.0\n",
      "2        0.0  Iris    RF     1.0\n",
      "3       -0.0  Iris    RF     1.0\n",
      "4        0.0  Iris    RF     1.0\n",
      "..       ...   ...   ...     ...\n",
      "145      0.0  Iris    RF     1.0\n",
      "146      0.0  Iris    RF     1.0\n",
      "147     -0.0  Iris    RF     1.0\n",
      "148     -0.0  Iris    RF     1.0\n",
      "149     -0.0  Iris    RF     1.0\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "estimator_tree=RandomForestClassifier()\n",
    "importance_func=None\n",
    "\n",
    "\n",
    "model_class_tree=imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_tree.fit()\n",
    "model_class_tree.consistency(data_name='Iris', estimator_name='RF',impotance_func_name='FI')\n",
    "print(model_class_tree.accuracy)\n",
    "print(model_class_tree.consistency)\n",
    "print(model_class_tree.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249d34a7",
   "metadata": {},
   "source": [
    "### Model agnostic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a5fcc",
   "metadata": {},
   "source": [
    "#### Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e52fd2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "1\n",
      "Iter:  1\n",
      "2\n",
      "Iter:  2\n",
      "Importance Function is  Permutation_RF\n",
      "   data model  Accuracy\n",
      "0  Iris    RF  0.822222\n",
      "1  Iris    RF  0.777778\n",
      "2  Iris    RF  0.933333\n",
      "   data          method criteria  K  Consistency  Accuracy\n",
      "0  Iris  Permutation_RF      RBO  1        0.500     0.844\n",
      "1  Iris  Permutation_RF      RBO  2        0.625     0.844\n",
      "2  Iris  Permutation_RF      RBO  3        0.694     0.844\n",
      "3  Iris  Permutation_RF      RBO  4        0.771     0.844\n",
      "4  Iris  Permutation_RF  Jaccard  1        0.500     0.844\n",
      "5  Iris  Permutation_RF  Jaccard  2        0.667     0.844\n",
      "6  Iris  Permutation_RF  Jaccard  3        0.750     0.844\n",
      "7  Iris  Permutation_RF  Jaccard  4        1.000     0.844\n",
      "     Entropy  data model  Purity\n",
      "0       -0.0  Iris    RF     1.0\n",
      "1       -0.0  Iris    RF     1.0\n",
      "2        0.0  Iris    RF     1.0\n",
      "3       -0.0  Iris    RF     1.0\n",
      "4        0.0  Iris    RF     1.0\n",
      "..       ...   ...   ...     ...\n",
      "145      0.0  Iris    RF     1.0\n",
      "146      0.0  Iris    RF     1.0\n",
      "147     -0.0  Iris    RF     1.0\n",
      "148     -0.0  Iris    RF     1.0\n",
      "149     -0.0  Iris    RF     1.0\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "estimator_tree=RandomForestClassifier()\n",
    "importance_func = permutation_importance ## change the importance function to be permutation \n",
    "\n",
    "\n",
    "model_class_tree_per=imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_tree_per.fit()\n",
    "model_class_tree_per.consistency(data_name='Iris', estimator_name='RF',impotance_func_name='Permutation')\n",
    "print(model_class_tree_per.accuracy)\n",
    "print(model_class_tree_per.consistency)\n",
    "print(model_class_tree_per.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d94c2a",
   "metadata": {},
   "source": [
    "#### Shapley Value \n",
    "\n",
    "###### error: cant import shap package, reinstall shap downgrade numpy to 1.21.6, while tensorflow needs 1.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12040c1a",
   "metadata": {},
   "source": [
    "we provide built-in importance functions from package shap and perumutation function from sklearn.inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a523a4",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "\n",
    "importance_func(self.fitted,x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878ef66",
   "metadata": {},
   "source": [
    "### MLP+DeepExplain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac0149",
   "metadata": {},
   "source": [
    "We have built-in functions to run functions from deepexplain and  deeplift packages. As well permutation and shapley values. User can either input a function or a string from [\n",
    "                        'zero',\n",
    "                        'saliency',\n",
    "                        'grad*input',\n",
    "                        'intgrad',\n",
    "                        'elrp',\n",
    "                        'deeplift',\n",
    "                        'occlusion',\n",
    "                        'shapley_sampling'] to run deepExplain. \n",
    "Or input strings from ['NonlinearMxtsMode.RevealCancel','NonlinearMxtsMode.GuidedBackprop'...] to run corresponding functions in deeplift. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094998a",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "    importance_func(model,x_train, y_train). Where model is .h5 file of MLP model. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927fc0ae",
   "metadata": {},
   "source": [
    "defined estimator needs to be form of :\n",
    "    def _base_model_classification():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9e26c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 17:19:03.089330: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-21 17:19:03.089350: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "None\n",
      "Iter:  0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'build_fn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_class_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoClass_MLP(data_class,\n\u001b[1;32m      6\u001b[0m                                                                            \n\u001b[1;32m      7\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mPermutationImportance,\n\u001b[1;32m      8\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m      9\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel_class_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model_class_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIris\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_class_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:906\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m yy_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(yy_train)\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermutation_importance\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m--> 906\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impo_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:819\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP._impo_score\u001b[0;34m(self, x_train, y_train, x_test)\u001b[0m\n\u001b[1;32m    816\u001b[0m impo_pack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermutation_importance\u001b[39m\u001b[38;5;124m'\u001b[39m,impo_pack):\n\u001b[1;32m    818\u001b[0m     \u001b[38;5;66;03m### need _base_model_classification instead of _base_model_classification()\u001b[39;00m\n\u001b[0;32m--> 819\u001b[0m     perm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuild_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_model_classification\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[1;32m    820\u001b[0m     s\u001b[38;5;241m=\u001b[39mperm\u001b[38;5;241m.\u001b[39mfeature_importances_\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;66;03m###### Loac MLP model\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'build_fn'"
     ]
    }
   ],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "importance_func =PermutationImportance\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "                 importance_func=PermutationImportance,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_mlp_dl.fit()\n",
    "model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_class_mlp_dl.accuracy)\n",
    "print(model_class_mlp_dl.consistency)\n",
    "print(model_class_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f739fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deepexplain package reuqires numpy =1.22.4, tf will have error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102ecea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deepexplain.tensorflow import DeepExplain\n",
    "# importance_func ='elrp'\n",
    "\n",
    "# ## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "# model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "#                  importance_func=importance_func,\n",
    "#                  n_repeat=3,split_proportion=0.7,\n",
    "#                 rand_index=1)\n",
    "# model_class_mlp_dl.fit()\n",
    "# model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "# print(model_class_mlp_dl.accuracy)\n",
    "# print(model_class_mlp_dl.consistency)\n",
    "# print(model_class_mlp_dl.prediction_consistency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b4c5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1847 - accuracy: 0.2467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x291cad970>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Activation\n",
    "M=len(x[0])\n",
    "num_class=3\n",
    "def _base_model_classification():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model  \n",
    "es = _base_model_classification()\n",
    "es.fit(x,pd.get_dummies(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53b956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1695 - accuracy: 0.2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:57:02.387240: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n",
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    fitted = es.fit(x,y)\n",
    "except:\n",
    "    fitted = es.fit(x,pd.get_dummies(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "901678a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eli5', 'sklearn', 'permutation_importance']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PermutationImportance.__module__.split('.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c90ad7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PermutationImportance\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[1;32m      4\u001b[0m my_model \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39m_base_model_classification)\n\u001b[1;32m      5\u001b[0m perm \u001b[38;5;241m=\u001b[39m PermutationImportance(my_model)\u001b[38;5;241m.\u001b[39mfit(x,y)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "my_model = KerasClassifier(build_fn=_base_model_classification)\n",
    "perm = PermutationImportance(my_model).fit(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e6983",
   "metadata": {},
   "source": [
    "### MLP+DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e834f87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Iter:  0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PermutationImportance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_class_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoClass_MLP(data_class,\n\u001b[1;32m      8\u001b[0m                                                                            \n\u001b[1;32m      9\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m     10\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     11\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel_class_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model_class_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIris\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_class_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:905\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    902\u001b[0m yy_test \u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(yy_test\u001b[38;5;241m.\u001b[39mreindex(columns \u001b[38;5;241m=\u001b[39m yy_train\u001b[38;5;241m.\u001b[39mcolumns, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    903\u001b[0m yy_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(yy_train)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_func \u001b[38;5;241m!=\u001b[39m\u001b[43mPermutationImportance\u001b[49m:\n\u001b[1;32m    907\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    908\u001b[0m         fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PermutationImportance' is not defined"
     ]
    }
   ],
   "source": [
    "from deeplift.layers import NonlinearMxtsMode\n",
    "import deeplift\n",
    "importance_func = 'NonlinearMxtsMode.RevealCancel'\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_mlp_dl.fit()\n",
    "model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_class_mlp_dl.accuracy)\n",
    "print(model_class_mlp_dl.consistency)\n",
    "print(model_class_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8832788c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cae499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
