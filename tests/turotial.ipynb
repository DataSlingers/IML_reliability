{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6dbe79e",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66faeb56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import imlreliability\n",
    "import pandas as pd\n",
    "import numpy as np#### Load Packages dir(imlreliability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0c6b96",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2efda92",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6520aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, normalize\n",
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Class']\n",
    "data =  pd.read_csv(csv_url, names = col_names)\n",
    "y =(data['Class'])\n",
    "x = data[['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']]\n",
    "\n",
    "### scale and normalize data \n",
    "x = normalize(scale(x))\n",
    "data_class=(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b9f852",
   "metadata": {},
   "source": [
    "### Model specific IML method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf777aea",
   "metadata": {},
   "source": [
    "#### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b952a95f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n",
      "3\n",
      "Iter:  3\n",
      "use coefs as feature importance \n",
      "4\n",
      "Iter:  4\n",
      "use coefs as feature importance \n",
      "5\n",
      "Iter:  5\n",
      "use coefs as feature importance \n",
      "6\n",
      "Iter:  6\n",
      "use coefs as feature importance \n",
      "7\n",
      "Iter:  7\n",
      "use coefs as feature importance \n",
      "8\n",
      "Iter:  8\n",
      "use coefs as feature importance \n",
      "9\n",
      "Iter:  9\n",
      "use coefs as feature importance \n",
      "Importance Function is  Coef_LogisticRidge\n",
      "   data          model  Accuracy\n",
      "0  Iris  LogisticRidge  0.822222\n",
      "1  Iris  LogisticRidge  0.777778\n",
      "2  Iris  LogisticRidge  0.933333\n",
      "3  Iris  LogisticRidge  0.844444\n",
      "4  Iris  LogisticRidge  0.888889\n",
      "5  Iris  LogisticRidge  0.866667\n",
      "6  Iris  LogisticRidge  0.866667\n",
      "7  Iris  LogisticRidge  0.911111\n",
      "8  Iris  LogisticRidge  0.777778\n",
      "9  Iris  LogisticRidge  0.755556\n",
      "   data              method criteria  K  Consistency  Accuracy\n",
      "0  Iris  Coef_LogisticRidge      RBO  1        0.778     0.844\n",
      "1  Iris  Coef_LogisticRidge      RBO  2        0.889     0.844\n",
      "2  Iris  Coef_LogisticRidge      RBO  3        0.926     0.844\n",
      "3  Iris  Coef_LogisticRidge      RBO  4        0.944     0.844\n",
      "4  Iris  Coef_LogisticRidge  Jaccard  1        0.778     0.844\n",
      "5  Iris  Coef_LogisticRidge  Jaccard  2        1.000     0.844\n",
      "6  Iris  Coef_LogisticRidge  Jaccard  3        1.000     0.844\n",
      "7  Iris  Coef_LogisticRidge  Jaccard  4        1.000     0.844\n",
      "   data          model   Entropy    Purity\n",
      "0  Iris  LogisticRidge  0.073236  0.894342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "estimator=LogisticRegressionCV()\n",
    "importance_func=None\n",
    "\n",
    "model_class = imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=10,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class.fit()\n",
    "model_class.consistency(data_name='Iris', estimator_name='LogisticRidge',impotance_func_name='Coef')\n",
    "print(model_class.accuracy)\n",
    "print(model_class.consistency)\n",
    "print(model_class.prediction_consistency)\n",
    "\n",
    "## model_class.consistency.to_csv('consis_test_fi_class.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f55df1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRidge</td>\n",
       "      <td>0.073236</td>\n",
       "      <td>0.894342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data          model   Entropy    Purity\n",
       "0  Iris  LogisticRidge  0.073236  0.894342"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.prediction_consistency.groupby(['data','model']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405d956",
   "metadata": {},
   "source": [
    "#### Tree-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac9022a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n",
      "Importance Function is  FI_RF\n",
      "   data model  Accuracy\n",
      "0  Iris    RF  0.822222\n",
      "1  Iris    RF  0.777778\n",
      "2  Iris    RF  0.933333\n",
      "   data method criteria  K  Consistency  Accuracy\n",
      "0  Iris  FI_RF      RBO  1        0.500     0.844\n",
      "1  Iris  FI_RF      RBO  2        0.750     0.844\n",
      "2  Iris  FI_RF      RBO  3        0.833     0.844\n",
      "3  Iris  FI_RF      RBO  4        0.875     0.844\n",
      "4  Iris  FI_RF  Jaccard  1        0.500     0.844\n",
      "5  Iris  FI_RF  Jaccard  2        1.000     0.844\n",
      "6  Iris  FI_RF  Jaccard  3        1.000     0.844\n",
      "7  Iris  FI_RF  Jaccard  4        1.000     0.844\n",
      "     Entropy  data model  Purity\n",
      "0       -0.0  Iris    RF     1.0\n",
      "1       -0.0  Iris    RF     1.0\n",
      "2        0.0  Iris    RF     1.0\n",
      "3       -0.0  Iris    RF     1.0\n",
      "4        0.0  Iris    RF     1.0\n",
      "..       ...   ...   ...     ...\n",
      "145      0.0  Iris    RF     1.0\n",
      "146      0.0  Iris    RF     1.0\n",
      "147     -0.0  Iris    RF     1.0\n",
      "148     -0.0  Iris    RF     1.0\n",
      "149     -0.0  Iris    RF     1.0\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "estimator_tree=RandomForestClassifier()\n",
    "importance_func=None\n",
    "\n",
    "\n",
    "model_class_tree=imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_tree.fit()\n",
    "model_class_tree.consistency(data_name='Iris', estimator_name='RF',impotance_func_name='FI')\n",
    "print(model_class_tree.accuracy)\n",
    "print(model_class_tree.consistency)\n",
    "print(model_class_tree.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f581447",
   "metadata": {},
   "source": [
    "### Model agnostic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2945ad6",
   "metadata": {},
   "source": [
    "#### Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e0fb34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "1\n",
      "Iter:  1\n",
      "2\n",
      "Iter:  2\n",
      "Importance Function is  Permutation_RF\n",
      "   data model  Accuracy\n",
      "0  Iris    RF  0.822222\n",
      "1  Iris    RF  0.777778\n",
      "2  Iris    RF  0.933333\n",
      "   data          method criteria  K  Consistency  Accuracy\n",
      "0  Iris  Permutation_RF      RBO  1        0.500     0.844\n",
      "1  Iris  Permutation_RF      RBO  2        0.625     0.844\n",
      "2  Iris  Permutation_RF      RBO  3        0.694     0.844\n",
      "3  Iris  Permutation_RF      RBO  4        0.771     0.844\n",
      "4  Iris  Permutation_RF  Jaccard  1        0.500     0.844\n",
      "5  Iris  Permutation_RF  Jaccard  2        0.667     0.844\n",
      "6  Iris  Permutation_RF  Jaccard  3        0.750     0.844\n",
      "7  Iris  Permutation_RF  Jaccard  4        1.000     0.844\n",
      "     Entropy  data model  Purity\n",
      "0       -0.0  Iris    RF     1.0\n",
      "1       -0.0  Iris    RF     1.0\n",
      "2        0.0  Iris    RF     1.0\n",
      "3       -0.0  Iris    RF     1.0\n",
      "4        0.0  Iris    RF     1.0\n",
      "..       ...   ...   ...     ...\n",
      "145      0.0  Iris    RF     1.0\n",
      "146      0.0  Iris    RF     1.0\n",
      "147     -0.0  Iris    RF     1.0\n",
      "148     -0.0  Iris    RF     1.0\n",
      "149     -0.0  Iris    RF     1.0\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "estimator_tree=RandomForestClassifier()\n",
    "importance_func = permutation_importance ## change the importance function to be permutation \n",
    "\n",
    "\n",
    "model_class_tree_per=imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_tree_per.fit()\n",
    "model_class_tree_per.consistency(data_name='Iris', estimator_name='RF',impotance_func_name='Permutation')\n",
    "print(model_class_tree_per.accuracy)\n",
    "print(model_class_tree_per.consistency)\n",
    "print(model_class_tree_per.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17efa94d",
   "metadata": {},
   "source": [
    "#### Shapley Value \n",
    "\n",
    "###### error: cant import shap package, reinstall shap downgrade numpy to 1.21.6, while tensorflow needs 1.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49beab73",
   "metadata": {},
   "source": [
    "we provide built-in importance functions from package shap and perumutation function from sklearn.inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca3c93",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "\n",
    "importance_func(self.fitted,x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83277b9e",
   "metadata": {},
   "source": [
    "### MLP+DeepExplain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d20162",
   "metadata": {},
   "source": [
    "We have built-in functions to run functions from deepexplain and  deeplift packages. As well permutation and shapley values. User can either input a function or a string from [\n",
    "                        'zero',\n",
    "                        'saliency',\n",
    "                        'grad*input',\n",
    "                        'intgrad',\n",
    "                        'elrp',\n",
    "                        'deeplift',\n",
    "                        'occlusion',\n",
    "                        'shapley_sampling'] to run deepExplain. \n",
    "Or input strings from ['NonlinearMxtsMode.RevealCancel','NonlinearMxtsMode.GuidedBackprop'...] to run corresponding functions in deeplift. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9266d81",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "    importance_func(model,x_train, y_train). Where model is .h5 file of MLP model. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b80eb5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Iter:  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_class_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoClass_MLP(data_class,\n\u001b[1;32m      6\u001b[0m                                                                            \n\u001b[1;32m      7\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m      8\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m      9\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel_class_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model_class_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIris\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_class_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:899\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    894\u001b[0m     x_train\u001b[38;5;241m=\u001b[39mnormalize(scale(x_train))\n\u001b[1;32m    895\u001b[0m     x_test \u001b[38;5;241m=\u001b[39mnormalize(scale(x_test))\n\u001b[0;32m--> 899\u001b[0m fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[1;32m    901\u001b[0m model_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mto_json()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1182\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1183\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1184\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1185\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1186\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1187\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1189\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/pc/y0x_8p995ljbj37pd_6xdgtm0000gp/T/__autograph_generated_filel22mpeiv.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "importance_func = 'elrp'\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_mlp_dl.fit()\n",
    "model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_class_mlp_dl.accuracy)\n",
    "print(model_class_mlp_dl.consistency)\n",
    "print(model_class_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68bb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2976b77",
   "metadata": {},
   "source": [
    "### MLP+DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07f04a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Metal device set to: Apple M1\n",
      "Iter:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:15:16.044164: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-21 16:15:16.044207: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-02-21 16:15:16.185046: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_class_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoClass_MLP(data_class,\n\u001b[1;32m      8\u001b[0m                                                                            \n\u001b[1;32m      9\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m     10\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     11\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel_class_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model_class_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIris\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_class_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:899\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    894\u001b[0m     x_train\u001b[38;5;241m=\u001b[39mnormalize(scale(x_train))\n\u001b[1;32m    895\u001b[0m     x_test \u001b[38;5;241m=\u001b[39mnormalize(scale(x_test))\n\u001b[0;32m--> 899\u001b[0m fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[1;32m    901\u001b[0m model_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mto_json()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1182\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1183\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1184\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1185\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1186\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1187\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1189\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/pc/y0x_8p995ljbj37pd_6xdgtm0000gp/T/__autograph_generated_filel22mpeiv.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from deeplift.layers import NonlinearMxtsMode\n",
    "import deeplift\n",
    "importance_func = 'NonlinearMxtsMode.RevealCancel'\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_mlp_dl.fit()\n",
    "model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_class_mlp_dl.accuracy)\n",
    "print(model_class_mlp_dl.consistency)\n",
    "print(model_class_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fdffae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a24be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
