{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39bfd22a",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66faeb56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import imlreliability\n",
    "import pandas as pd\n",
    "import numpy as np#### Load Packages dir(imlreliability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4c5c1",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d3bcd",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5de8bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, normalize\n",
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Class']\n",
    "data =  pd.read_csv(csv_url, names = col_names)\n",
    "y =(data['Class'])\n",
    "x = data[['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']]\n",
    "\n",
    "### scale and normalize data \n",
    "x = normalize(scale(x))\n",
    "data_class=(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea52269",
   "metadata": {},
   "source": [
    "### Model specific IML method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73825a61",
   "metadata": {},
   "source": [
    "#### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bdc8142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n",
      "3\n",
      "Iter:  3\n",
      "use coefs as feature importance \n",
      "4\n",
      "Iter:  4\n",
      "use coefs as feature importance \n",
      "5\n",
      "Iter:  5\n",
      "use coefs as feature importance \n",
      "6\n",
      "Iter:  6\n",
      "use coefs as feature importance \n",
      "7\n",
      "Iter:  7\n",
      "use coefs as feature importance \n",
      "8\n",
      "Iter:  8\n",
      "use coefs as feature importance \n",
      "9\n",
      "Iter:  9\n",
      "use coefs as feature importance \n",
      "Importance Function is  Coef_LogisticRidge\n",
      "   data          model  Accuracy\n",
      "0  Iris  LogisticRidge  0.822222\n",
      "1  Iris  LogisticRidge  0.777778\n",
      "2  Iris  LogisticRidge  0.933333\n",
      "3  Iris  LogisticRidge  0.844444\n",
      "4  Iris  LogisticRidge  0.888889\n",
      "5  Iris  LogisticRidge  0.866667\n",
      "6  Iris  LogisticRidge  0.866667\n",
      "7  Iris  LogisticRidge  0.911111\n",
      "8  Iris  LogisticRidge  0.777778\n",
      "9  Iris  LogisticRidge  0.755556\n",
      "   data              method criteria  K  Consistency  Accuracy\n",
      "0  Iris  Coef_LogisticRidge      RBO  1        0.778     0.844\n",
      "1  Iris  Coef_LogisticRidge      RBO  2        0.889     0.844\n",
      "2  Iris  Coef_LogisticRidge      RBO  3        0.926     0.844\n",
      "3  Iris  Coef_LogisticRidge      RBO  4        0.944     0.844\n",
      "4  Iris  Coef_LogisticRidge  Jaccard  1        0.778     0.844\n",
      "5  Iris  Coef_LogisticRidge  Jaccard  2        1.000     0.844\n",
      "6  Iris  Coef_LogisticRidge  Jaccard  3        1.000     0.844\n",
      "7  Iris  Coef_LogisticRidge  Jaccard  4        1.000     0.844\n",
      "   data          model   Entropy    Purity\n",
      "0  Iris  LogisticRidge  0.073236  0.894342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "estimator=LogisticRegressionCV()\n",
    "importance_func=None\n",
    "\n",
    "model_class = imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=10,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class.fit()\n",
    "model_class.consistency(data_name='Iris', estimator_name='LogisticRidge',impotance_func_name='Coef')\n",
    "print(model_class.accuracy)\n",
    "print(model_class.consistency)\n",
    "print(model_class.prediction_consistency)\n",
    "\n",
    "## model_class.consistency.to_csv('consis_test_fi_class.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40446825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRidge</td>\n",
       "      <td>0.073236</td>\n",
       "      <td>0.894342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data          model   Entropy    Purity\n",
       "0  Iris  LogisticRidge  0.073236  0.894342"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.prediction_consistency.groupby(['data','model']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c67780",
   "metadata": {},
   "source": [
    "#### Tree-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90a0f15b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n",
      "Importance Function is  FI_RF\n",
      "   data model  Accuracy\n",
      "0  Iris    RF  0.822222\n",
      "1  Iris    RF  0.777778\n",
      "2  Iris    RF  0.933333\n",
      "   data method criteria  K  Consistency  Accuracy\n",
      "0  Iris  FI_RF      RBO  1        0.500     0.844\n",
      "1  Iris  FI_RF      RBO  2        0.750     0.844\n",
      "2  Iris  FI_RF      RBO  3        0.833     0.844\n",
      "3  Iris  FI_RF      RBO  4        0.875     0.844\n",
      "4  Iris  FI_RF  Jaccard  1        0.500     0.844\n",
      "5  Iris  FI_RF  Jaccard  2        1.000     0.844\n",
      "6  Iris  FI_RF  Jaccard  3        1.000     0.844\n",
      "7  Iris  FI_RF  Jaccard  4        1.000     0.844\n",
      "     Entropy  data model  Purity\n",
      "0       -0.0  Iris    RF     1.0\n",
      "1       -0.0  Iris    RF     1.0\n",
      "2        0.0  Iris    RF     1.0\n",
      "3       -0.0  Iris    RF     1.0\n",
      "4        0.0  Iris    RF     1.0\n",
      "..       ...   ...   ...     ...\n",
      "145      0.0  Iris    RF     1.0\n",
      "146      0.0  Iris    RF     1.0\n",
      "147     -0.0  Iris    RF     1.0\n",
      "148     -0.0  Iris    RF     1.0\n",
      "149     -0.0  Iris    RF     1.0\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "estimator_tree=RandomForestClassifier()\n",
    "importance_func=None\n",
    "\n",
    "\n",
    "model_class_tree=imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_tree.fit()\n",
    "model_class_tree.consistency(data_name='Iris', estimator_name='RF',impotance_func_name='FI')\n",
    "print(model_class_tree.accuracy)\n",
    "print(model_class_tree.consistency)\n",
    "print(model_class_tree.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eefad4",
   "metadata": {},
   "source": [
    "### Model agnostic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec47f2f",
   "metadata": {},
   "source": [
    "#### Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "078b97f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "1\n",
      "Iter:  1\n",
      "2\n",
      "Iter:  2\n",
      "Importance Function is  Permutation_RF\n",
      "   data model  Accuracy\n",
      "0  Iris    RF  0.822222\n",
      "1  Iris    RF  0.777778\n",
      "2  Iris    RF  0.933333\n",
      "   data          method criteria  K  Consistency  Accuracy\n",
      "0  Iris  Permutation_RF      RBO  1        0.500     0.844\n",
      "1  Iris  Permutation_RF      RBO  2        0.625     0.844\n",
      "2  Iris  Permutation_RF      RBO  3        0.694     0.844\n",
      "3  Iris  Permutation_RF      RBO  4        0.771     0.844\n",
      "4  Iris  Permutation_RF  Jaccard  1        0.500     0.844\n",
      "5  Iris  Permutation_RF  Jaccard  2        0.667     0.844\n",
      "6  Iris  Permutation_RF  Jaccard  3        0.750     0.844\n",
      "7  Iris  Permutation_RF  Jaccard  4        1.000     0.844\n",
      "     Entropy  data model  Purity\n",
      "0       -0.0  Iris    RF     1.0\n",
      "1       -0.0  Iris    RF     1.0\n",
      "2        0.0  Iris    RF     1.0\n",
      "3       -0.0  Iris    RF     1.0\n",
      "4        0.0  Iris    RF     1.0\n",
      "..       ...   ...   ...     ...\n",
      "145      0.0  Iris    RF     1.0\n",
      "146      0.0  Iris    RF     1.0\n",
      "147     -0.0  Iris    RF     1.0\n",
      "148     -0.0  Iris    RF     1.0\n",
      "149     -0.0  Iris    RF     1.0\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "estimator_tree=RandomForestClassifier()\n",
    "importance_func = permutation_importance ## change the importance function to be permutation \n",
    "\n",
    "\n",
    "model_class_tree_per=imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_tree_per.fit()\n",
    "model_class_tree_per.consistency(data_name='Iris', estimator_name='RF',impotance_func_name='Permutation')\n",
    "print(model_class_tree_per.accuracy)\n",
    "print(model_class_tree_per.consistency)\n",
    "print(model_class_tree_per.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55248c4e",
   "metadata": {},
   "source": [
    "#### Shapley Value \n",
    "\n",
    "###### error: cant import shap package, reinstall shap downgrade numpy to 1.21.6, while tensorflow needs 1.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c1bf2",
   "metadata": {},
   "source": [
    "we provide built-in importance functions from package shap and perumutation function from sklearn.inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df83e5",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "\n",
    "importance_func(self.fitted,x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a7c8e2",
   "metadata": {},
   "source": [
    "### MLP+DeepExplain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bffb99",
   "metadata": {},
   "source": [
    "We have built-in functions to run functions from deepexplain and  deeplift packages. As well permutation and shapley values. User can either input a function or a string from [\n",
    "                        'zero',\n",
    "                        'saliency',\n",
    "                        'grad*input',\n",
    "                        'intgrad',\n",
    "                        'elrp',\n",
    "                        'deeplift',\n",
    "                        'occlusion',\n",
    "                        'shapley_sampling'] to run deepExplain. \n",
    "Or input strings from ['NonlinearMxtsMode.RevealCancel','NonlinearMxtsMode.GuidedBackprop'...] to run corresponding functions in deeplift. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6521082",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "    importance_func(model,x_train, y_train). Where model is .h5 file of MLP model. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5714038b",
   "metadata": {},
   "source": [
    "defined estimator needs to be form of :\n",
    "    def _base_model_classification():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c506576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Iter:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:22:54.379472: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model_class_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoClass_MLP(data_class,\n\u001b[1;32m      7\u001b[0m                                                                            \n\u001b[1;32m      8\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m      9\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     10\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel_class_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model_class_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIris\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_class_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:905\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 905\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43myy_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[1;32m    907\u001b[0m model_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mto_json()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1182\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1183\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1184\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1185\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1186\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1187\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1189\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:921\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    919\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    920\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    926\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "importance_func =permutation_importance\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_mlp_dl.fit()\n",
    "model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_class_mlp_dl.accuracy)\n",
    "print(model_class_mlp_dl.consistency)\n",
    "print(model_class_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e09f0f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Iter:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:23:11.742276: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model_class_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoClass_MLP(data_class,\n\u001b[1;32m      7\u001b[0m                                                                            \n\u001b[1;32m      8\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m      9\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     10\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mmodel_class_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model_class_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIris\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_class_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:905\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 905\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43myy_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[1;32m    907\u001b[0m model_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mto_json()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1182\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1183\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1184\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1185\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1186\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1187\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1189\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:921\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    919\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    920\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    926\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "importance_func ='elrp'\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_mlp_dl.fit()\n",
    "model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_class_mlp_dl.accuracy)\n",
    "print(model_class_mlp_dl.consistency)\n",
    "print(model_class_mlp_dl.prediction_consistency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f5c3dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/5 [=====>........................] - ETA: 0s - loss: 1.1588 - accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:44:36.895643: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 36ms/step - loss: 1.1845 - accuracy: 0.2533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x29d79efa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Activation\n",
    "M=len(x[0])\n",
    "num_class=3\n",
    "def _base_model_classification():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model  \n",
    "es = _base_model_classification()\n",
    "es.fit(x,pd.get_dummies(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f793b0",
   "metadata": {},
   "source": [
    "### MLP+DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3be97752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Iter:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:22:01.711972: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_class_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoClass_MLP(data_class,\n\u001b[1;32m      8\u001b[0m                                                                            \n\u001b[1;32m      9\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m     10\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     11\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel_class_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model_class_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIris\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_class_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:905\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit(x_train,y_train)\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 905\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43myy_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m##########\u001b[39;00m\n\u001b[1;32m    907\u001b[0m model_json \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mto_json()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1182\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1183\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1184\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1185\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1186\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1187\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1189\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:921\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    919\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    920\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    926\u001b[0m   \u001b[38;5;66;03m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "from deeplift.layers import NonlinearMxtsMode\n",
    "import deeplift\n",
    "importance_func = NonlinearMxtsMode.RevealCancel\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_mlp_dl.fit()\n",
    "model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_class_mlp_dl.accuracy)\n",
    "print(model_class_mlp_dl.consistency)\n",
    "print(model_class_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc79d399",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1187\u001b[0m tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/pc/y0x_8p995ljbj37pd_6xdgtm0000gp/T/__autograph_generated_file9j_otapg.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m es\u001b[38;5;241m.\u001b[39mfit(x,y)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m es\u001b[38;5;241m.\u001b[39mfit(x,\u001b[43myy\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yy' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    fitted = es.fit(x,y)\n",
    "except:\n",
    "    fitted = es.fit(x,yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1fb20c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
