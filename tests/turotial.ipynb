{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a97e1aa",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66faeb56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import imlreliability\n",
    "import pandas as pd\n",
    "import numpy as np#### Load Packages dir(imlreliability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c0e962",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff386d",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed19dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, normalize\n",
    "csv_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "col_names = ['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width','Class']\n",
    "data =  pd.read_csv(csv_url, names = col_names)\n",
    "y =(data['Class'])\n",
    "x = data[['Sepal_Length','Sepal_Width','Petal_Length','Petal_Width']]\n",
    "\n",
    "### scale and normalize data \n",
    "x = normalize(scale(x))\n",
    "data_class=(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ab2b15",
   "metadata": {},
   "source": [
    "### Model specific IML method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48626147",
   "metadata": {},
   "source": [
    "#### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "707b118a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n",
      "3\n",
      "Iter:  3\n",
      "use coefs as feature importance \n",
      "4\n",
      "Iter:  4\n",
      "use coefs as feature importance \n",
      "5\n",
      "Iter:  5\n",
      "use coefs as feature importance \n",
      "6\n",
      "Iter:  6\n",
      "use coefs as feature importance \n",
      "7\n",
      "Iter:  7\n",
      "use coefs as feature importance \n",
      "8\n",
      "Iter:  8\n",
      "use coefs as feature importance \n",
      "9\n",
      "Iter:  9\n",
      "use coefs as feature importance \n",
      "Importance Function is  Coef_LogisticRidge\n",
      "   data          model  Accuracy\n",
      "0  Iris  LogisticRidge  0.822222\n",
      "1  Iris  LogisticRidge  0.777778\n",
      "2  Iris  LogisticRidge  0.933333\n",
      "3  Iris  LogisticRidge  0.844444\n",
      "4  Iris  LogisticRidge  0.888889\n",
      "5  Iris  LogisticRidge  0.866667\n",
      "6  Iris  LogisticRidge  0.866667\n",
      "7  Iris  LogisticRidge  0.911111\n",
      "8  Iris  LogisticRidge  0.777778\n",
      "9  Iris  LogisticRidge  0.755556\n",
      "   data              method criteria  K  Consistency  Accuracy\n",
      "0  Iris  Coef_LogisticRidge      RBO  1        0.778     0.844\n",
      "1  Iris  Coef_LogisticRidge      RBO  2        0.889     0.844\n",
      "2  Iris  Coef_LogisticRidge      RBO  3        0.926     0.844\n",
      "3  Iris  Coef_LogisticRidge      RBO  4        0.944     0.844\n",
      "4  Iris  Coef_LogisticRidge  Jaccard  1        0.778     0.844\n",
      "5  Iris  Coef_LogisticRidge  Jaccard  2        1.000     0.844\n",
      "6  Iris  Coef_LogisticRidge  Jaccard  3        1.000     0.844\n",
      "7  Iris  Coef_LogisticRidge  Jaccard  4        1.000     0.844\n",
      "   data          model   Entropy    Purity\n",
      "0  Iris  LogisticRidge  0.073236  0.894342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "estimator=LogisticRegressionCV()\n",
    "importance_func=None\n",
    "\n",
    "model_class = imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=10,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class.fit()\n",
    "model_class.consistency(data_name='Iris', estimator_name='LogisticRidge',impotance_func_name='Coef')\n",
    "print(model_class.accuracy)\n",
    "print(model_class.consistency)\n",
    "print(model_class.prediction_consistency)\n",
    "\n",
    "## model_class.consistency.to_csv('consis_test_fi_class.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e38b4dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>model</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>LogisticRidge</td>\n",
       "      <td>0.073236</td>\n",
       "      <td>0.894342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data          model   Entropy    Purity\n",
       "0  Iris  LogisticRidge  0.073236  0.894342"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.prediction_consistency.groupby(['data','model']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680c13ab",
   "metadata": {},
   "source": [
    "#### Tree-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923dab4f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "use coefs as feature importance \n",
      "1\n",
      "Iter:  1\n",
      "use coefs as feature importance \n",
      "2\n",
      "Iter:  2\n",
      "use coefs as feature importance \n",
      "Importance Function is  FI_RF\n",
      "   data model  Accuracy\n",
      "0  Iris    RF  0.822222\n",
      "1  Iris    RF  0.777778\n",
      "2  Iris    RF  0.933333\n",
      "   data method criteria  K  Consistency  Accuracy\n",
      "0  Iris  FI_RF      RBO  1        0.500     0.844\n",
      "1  Iris  FI_RF      RBO  2        0.750     0.844\n",
      "2  Iris  FI_RF      RBO  3        0.833     0.844\n",
      "3  Iris  FI_RF      RBO  4        0.875     0.844\n",
      "4  Iris  FI_RF  Jaccard  1        0.500     0.844\n",
      "5  Iris  FI_RF  Jaccard  2        1.000     0.844\n",
      "6  Iris  FI_RF  Jaccard  3        1.000     0.844\n",
      "7  Iris  FI_RF  Jaccard  4        1.000     0.844\n",
      "     Entropy  data model  Purity\n",
      "0       -0.0  Iris    RF     1.0\n",
      "1       -0.0  Iris    RF     1.0\n",
      "2        0.0  Iris    RF     1.0\n",
      "3       -0.0  Iris    RF     1.0\n",
      "4        0.0  Iris    RF     1.0\n",
      "..       ...   ...   ...     ...\n",
      "145      0.0  Iris    RF     1.0\n",
      "146      0.0  Iris    RF     1.0\n",
      "147     -0.0  Iris    RF     1.0\n",
      "148     -0.0  Iris    RF     1.0\n",
      "149     -0.0  Iris    RF     1.0\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "estimator_tree=RandomForestClassifier()\n",
    "importance_func=None\n",
    "\n",
    "\n",
    "model_class_tree=imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_tree.fit()\n",
    "model_class_tree.consistency(data_name='Iris', estimator_name='RF',impotance_func_name='FI')\n",
    "print(model_class_tree.accuracy)\n",
    "print(model_class_tree.consistency)\n",
    "print(model_class_tree.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9295e63",
   "metadata": {},
   "source": [
    "### Model agnostic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad455dfa",
   "metadata": {},
   "source": [
    "#### Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cecee1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iter:  0\n",
      "1\n",
      "Iter:  1\n",
      "2\n",
      "Iter:  2\n",
      "Importance Function is  Permutation_RF\n",
      "   data model  Accuracy\n",
      "0  Iris    RF  0.822222\n",
      "1  Iris    RF  0.777778\n",
      "2  Iris    RF  0.933333\n",
      "   data          method criteria  K  Consistency  Accuracy\n",
      "0  Iris  Permutation_RF      RBO  1        0.500     0.844\n",
      "1  Iris  Permutation_RF      RBO  2        0.625     0.844\n",
      "2  Iris  Permutation_RF      RBO  3        0.694     0.844\n",
      "3  Iris  Permutation_RF      RBO  4        0.771     0.844\n",
      "4  Iris  Permutation_RF  Jaccard  1        0.500     0.844\n",
      "5  Iris  Permutation_RF  Jaccard  2        0.667     0.844\n",
      "6  Iris  Permutation_RF  Jaccard  3        0.750     0.844\n",
      "7  Iris  Permutation_RF  Jaccard  4        1.000     0.844\n",
      "     Entropy  data model  Purity\n",
      "0       -0.0  Iris    RF     1.0\n",
      "1       -0.0  Iris    RF     1.0\n",
      "2        0.0  Iris    RF     1.0\n",
      "3       -0.0  Iris    RF     1.0\n",
      "4        0.0  Iris    RF     1.0\n",
      "..       ...   ...   ...     ...\n",
      "145      0.0  Iris    RF     1.0\n",
      "146      0.0  Iris    RF     1.0\n",
      "147     -0.0  Iris    RF     1.0\n",
      "148     -0.0  Iris    RF     1.0\n",
      "149     -0.0  Iris    RF     1.0\n",
      "\n",
      "[150 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "estimator_tree=RandomForestClassifier()\n",
    "importance_func = permutation_importance ## change the importance function to be permutation \n",
    "\n",
    "\n",
    "model_class_tree_per=imlreliability.feature_importance.feature_impoClass(data_class,estimator,sigma=1,\n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_tree_per.fit()\n",
    "model_class_tree_per.consistency(data_name='Iris', estimator_name='RF',impotance_func_name='Permutation')\n",
    "print(model_class_tree_per.accuracy)\n",
    "print(model_class_tree_per.consistency)\n",
    "print(model_class_tree_per.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c612a816",
   "metadata": {},
   "source": [
    "#### Shapley Value \n",
    "\n",
    "###### error: cant import shap package, reinstall shap downgrade numpy to 1.21.6, while tensorflow needs 1.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5893b52b",
   "metadata": {},
   "source": [
    "we provide built-in importance functions from package shap and perumutation function from sklearn.inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a2925d",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "\n",
    "importance_func(self.fitted,x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fcfb10",
   "metadata": {},
   "source": [
    "### MLP+DeepExplain "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e23f02",
   "metadata": {},
   "source": [
    "We have built-in functions to run functions from deepexplain and  deeplift packages. As well permutation and shapley values. User can either input a function or a string from [\n",
    "                        'zero',\n",
    "                        'saliency',\n",
    "                        'grad*input',\n",
    "                        'intgrad',\n",
    "                        'elrp',\n",
    "                        'deeplift',\n",
    "                        'occlusion',\n",
    "                        'shapley_sampling'] to run deepExplain. \n",
    "Or input strings from ['NonlinearMxtsMode.RevealCancel','NonlinearMxtsMode.GuidedBackprop'...] to run corresponding functions in deeplift. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a9ec61",
   "metadata": {},
   "source": [
    "Can also ues self-defined importance function, with three argument: (fitted model, training x, training y), and 1 output importance score in forms of list or array. \n",
    "    importance_func(model,x_train, y_train). Where model is .h5 file of MLP model. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96913e2",
   "metadata": {},
   "source": [
    "defined estimator needs to be form of :\n",
    "    def _base_model_classification():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e7ff659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:55:53.314567: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-21 16:55:53.314627: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "2023-02-21 16:55:53.431376: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-21 16:55:53.460048: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "None\n",
      "Iter:  0\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.1063 - accuracy: 0.3143\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x28608d0d0> does not.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model_class_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoClass_MLP(data_class,\n\u001b[1;32m      6\u001b[0m                                                                            \n\u001b[1;32m      7\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m      8\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m      9\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel_class_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m model_class_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIris\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_class_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:919\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_file\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 919\u001b[0m         ss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impo_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m##### different in MLP!\u001b[39;00m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:831\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP._impo_score\u001b[0;34m(self, x_train, y_train, x_test)\u001b[0m\n\u001b[1;32m    828\u001b[0m             s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_func(model, background)\u001b[38;5;241m.\u001b[39mshap_values(x_test)\n\u001b[1;32m    829\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m    830\u001b[0m             \u001b[38;5;66;03m##user defined function \u001b[39;00m\n\u001b[0;32m--> 831\u001b[0m             s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimportance_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m## if input is string \u001b[39;00m\n\u001b[1;32m    834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_func,de_methods):        \n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/inspection/_permutation_importance.py:252\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[0;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[1;32m    250\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m scoring\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m scoring \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scoring, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 252\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    254\u001b[0m     scorers_dict \u001b[38;5;241m=\u001b[39m _check_multimetric_scoring(estimator, scoring)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py:488\u001b[0m, in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    489\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf no scoring is specified, the estimator passed should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    490\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m method. The estimator \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m estimator\n\u001b[1;32m    491\u001b[0m         )\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scoring, Iterable):\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    494\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor evaluating multiple scores, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection.cross_validate instead. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m was passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scoring)\n\u001b[1;32m    497\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: If no scoring is specified, the estimator passed should have a 'score' method. The estimator <tensorflow.python.keras.engine.sequential.Sequential object at 0x28608d0d0> does not."
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "importance_func =PermutationImportance\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_mlp_dl.fit()\n",
    "model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_class_mlp_dl.accuracy)\n",
    "print(model_class_mlp_dl.consistency)\n",
    "print(model_class_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d5c50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## deepexplain package reuqires numpy =1.22.4, tf will have error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3ee2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from deepexplain.tensorflow import DeepExplain\n",
    "# importance_func ='elrp'\n",
    "\n",
    "# ## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "# model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "#                  importance_func=importance_func,\n",
    "#                  n_repeat=3,split_proportion=0.7,\n",
    "#                 rand_index=1)\n",
    "# model_class_mlp_dl.fit()\n",
    "# model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "# print(model_class_mlp_dl.accuracy)\n",
    "# print(model_class_mlp_dl.consistency)\n",
    "# print(model_class_mlp_dl.prediction_consistency)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027cfa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 18ms/step - loss: 1.1847 - accuracy: 0.2467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x291cad970>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.layers import Dense, Activation\n",
    "M=len(x[0])\n",
    "num_class=3\n",
    "def _base_model_classification():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "    model.add(Dense(M, input_dim=M, activation='relu'))\n",
    "\n",
    "    model.add(Dense(num_class, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model  \n",
    "es = _base_model_classification()\n",
    "es.fit(x,pd.get_dummies(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "973b343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1695 - accuracy: 0.2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 16:57:02.387240: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n",
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    fitted = es.fit(x,y)\n",
    "except:\n",
    "    fitted = es.fit(x,pd.get_dummies(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94de7269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eli5', 'sklearn', 'permutation_importance']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PermutationImportance.__module__.split('.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02c98057",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01meli5\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PermutationImportance\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[1;32m      4\u001b[0m my_model \u001b[38;5;241m=\u001b[39m KerasClassifier(build_fn\u001b[38;5;241m=\u001b[39m_base_model_classification)\n\u001b[1;32m      5\u001b[0m perm \u001b[38;5;241m=\u001b[39m PermutationImportance(my_model)\u001b[38;5;241m.\u001b[39mfit(x,y)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "from eli5.sklearn import PermutationImportance\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "my_model = KerasClassifier(build_fn=_base_model_classification)\n",
    "perm = PermutationImportance(my_model).fit(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680abd69",
   "metadata": {},
   "source": [
    "### MLP+DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48af8115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "None\n",
      "Iter:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 17:09:28.544006: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-21 17:09:28.544052: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "/Users/melinda/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "2023-02-21 17:09:28.654473: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-02-21 17:09:28.677909: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0605 - accuracy: 0.4000\n",
      "Invalid feature importance function\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 's' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model_class_mlp_dl\u001b[38;5;241m=\u001b[39mimlreliability\u001b[38;5;241m.\u001b[39mfeature_importance\u001b[38;5;241m.\u001b[39mfeature_impoClass_MLP(data_class,\n\u001b[1;32m      8\u001b[0m                                                                            \n\u001b[1;32m      9\u001b[0m                  importance_func\u001b[38;5;241m=\u001b[39mimportance_func,\n\u001b[1;32m     10\u001b[0m                  n_repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,split_proportion\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     11\u001b[0m                 rand_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel_class_mlp_dl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model_class_mlp_dl\u001b[38;5;241m.\u001b[39mconsistency(data_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIris\u001b[39m\u001b[38;5;124m'\u001b[39m, estimator_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m,impotance_func_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeepLift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_class_mlp_dl\u001b[38;5;241m.\u001b[39maccuracy)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:919\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;66;03m######################\u001b[39;00m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msaved_model_file\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 919\u001b[0m         ss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impo_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m##### different in MLP!\u001b[39;00m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IML_reliability-0.1-py3.9.egg/imlreliability/feature_importance/_feature_impo.py:876\u001b[0m, in \u001b[0;36mfeature_impoClass_MLP._impo_score\u001b[0;34m(self, x_train, y_train, x_test)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    875\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid feature importance function\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_score(\u001b[43ms\u001b[49m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 's' referenced before assignment"
     ]
    }
   ],
   "source": [
    "from deeplift.layers import NonlinearMxtsMode\n",
    "import deeplift\n",
    "importance_func = NonlinearMxtsMode.RevealCancel\n",
    "\n",
    "## Two-layer default MLP will be computed if estimator =None. Can input user-defined MLP model\n",
    "\n",
    "model_class_mlp_dl=imlreliability.feature_importance.feature_impoClass_MLP(data_class,\n",
    "                                                                           \n",
    "                 importance_func=importance_func,\n",
    "                 n_repeat=3,split_proportion=0.7,\n",
    "                rand_index=1)\n",
    "model_class_mlp_dl.fit()\n",
    "model_class_mlp_dl.consistency(data_name='Iris', estimator_name='MLP',impotance_func_name='DeepLift')\n",
    "print(model_class_mlp_dl.accuracy)\n",
    "print(model_class_mlp_dl.consistency)\n",
    "print(model_class_mlp_dl.prediction_consistency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14711147",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'yy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1187\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1186\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1187\u001b[0m tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/pc/y0x_8p995ljbj37pd_6xdgtm0000gp/T/__autograph_generated_file9j_otapg.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m es\u001b[38;5;241m.\u001b[39mfit(x,y)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m----> 4\u001b[0m     fitted \u001b[38;5;241m=\u001b[39m es\u001b[38;5;241m.\u001b[39mfit(x,\u001b[43myy\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'yy' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c88fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(deeplift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f548324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
